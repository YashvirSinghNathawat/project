{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statement\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file\n",
    "with open('hi_100.txt', encoding='utf-8') as f:\n",
    "    # Read the content of the file and split it into lines\n",
    "    dataset = f.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for line in dataset:\n",
    "    words = line.split()\n",
    "    data.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "आ\n",
      "व\n",
      "े\n",
      "द\n",
      "न\n"
     ]
    }
   ],
   "source": [
    "# लकड़ी जनतंत्र अँगना\n",
    "'''\n",
    "क्ष = क् + ष् + अ\n",
    "त्र = त् + र्  + अ\n",
    "ज्ञ = ज् + ञ् + अ\n",
    "श्र = श् + र्  + अ\n",
    "'''\n",
    "word = 'आवेदन'\n",
    "dict = {'त्र' : ['क्','ष्','अ']}\n",
    "for ch in word:\n",
    "    for c in ch:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "consonents = {\n",
    "    'क': 'क्',  # ka\n",
    "    'ख': 'ख्',  # kha\n",
    "    'ग': 'ग्',  # ga\n",
    "    'घ': 'घ्',  # gha\n",
    "    'ङ': 'ङ्',  # ṅa\n",
    "    'च': 'च्',  # ca\n",
    "    'छ': 'छ्',  # cha\n",
    "    'ज': 'ज्',  # ja\n",
    "    'झ': 'झ्',  # jha\n",
    "    'ञ': 'ञ्',  # ña\n",
    "    'ट': 'ट्',  # ṭa\n",
    "    'ठ': 'ठ्',  # ṭha\n",
    "    'ड': 'ड्',  # ḍa\n",
    "    'ढ': 'ढ्',  # ḍha\n",
    "    'ण': 'ण्',  # ṇa\n",
    "    'त': 'त्',  # ta\n",
    "    'थ': 'थ्',  # tha\n",
    "    'द': 'द्',  # da\n",
    "    'ध': 'ध्',  # dha\n",
    "    'न': 'न्',  # na\n",
    "    'प': 'प्',  # pa\n",
    "    'फ': 'फ्',  # pha\n",
    "    'ब': 'ब्',  # ba\n",
    "    'भ': 'भ्',  # bha\n",
    "    'म': 'म्',  # ma\n",
    "    'य': 'य्',  # ya\n",
    "    'र': 'र्',  # ra\n",
    "    'ल': 'ल्',  # la\n",
    "    'व': 'व्',  # va\n",
    "    'श': 'श्',  # śa\n",
    "    'ष': 'ष्',  # ṣa\n",
    "    'स': 'स्',  # sa\n",
    "    'ह': 'ह्',  # ha\n",
    "}\n",
    "halant = 'अ' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of Devanagari vowel signs to their vowels\n",
    "sign_mapping_vowels = {\n",
    "    'ा': 'आ',  # Aa\n",
    "    'ि': 'इ',  # I\n",
    "    'ी': 'ई',  # II\n",
    "    'ु': 'उ',  # U\n",
    "    'ू': 'ऊ',  # UU\n",
    "    'ृ': 'ऋ',  # R\n",
    "    'े': 'ए',  # E\n",
    "    'ै': 'ऐ',  # AI\n",
    "    'ो': 'ओ',  # O\n",
    "    'ौ': 'औ',  # AU\n",
    "    'ं': 'अं', # Anusvara\n",
    "    'ः': 'अः',  # Visarga\n",
    "    'ँ': 'अँ',\n",
    "    '़': '़'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert the dictionary key to value\n",
    "sign_mapping_vowels_reversed = {value: key for key, value in sign_mapping_vowels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all vowels in Hindi\n",
    "devanagari_vowels = ['अ', 'अं','आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऌ', 'ऍ', 'ऎ', 'ए', 'ऐ', 'ऑ', 'ऒ', 'ओ', 'औ']\n",
    "hindi_half_forms = ['क्', 'ख्', 'ग्', 'घ्', 'ङ्', 'च्', 'छ्', 'ज्', 'झ्', 'ञ्', 'ट्', 'ठ्', 'ड्', 'ढ्', 'ण्', 'त्', 'थ्', 'द्', 'ध्', 'न्', 'प्', 'फ्', 'ब्', 'भ्', 'म्', 'य्', 'र्', 'ल्', 'व्', 'श्', 'ष्', 'स्', 'ह्']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'क्', 'ऐ', 'अं', 'स्', 'अ', 'र्', 'अ', ' ']\n"
     ]
    }
   ],
   "source": [
    "# Function to do varn viched\n",
    "def do_varn_viched(word):\n",
    "    halant_forms = []\n",
    "    # Iterate over each character in the input string\n",
    "    str_len = len(word)\n",
    "    i = 0\n",
    "    while(i<str_len):\n",
    "        # Check if the character is in the dictionary\n",
    "        if word[i] in consonents:\n",
    "            # If the character is found, append both the character and its half form with halant\n",
    "\n",
    "            # Special Case\n",
    "            if i+2<str_len and word[i]=='त' and word[i+1]=='्' and word[i+2]=='र':\n",
    "                halant_forms.append('त्')\n",
    "                halant_forms.append('र्')\n",
    "                i+=3\n",
    "                if i<str_len and word[i] in sign_mapping_vowels:\n",
    "                    halant_forms.append(sign_mapping_vowels[word[i]])\n",
    "                    i+=1\n",
    "                else:\n",
    "                    halant_forms.append(halant)\n",
    "                continue\n",
    "            if i+2<str_len and word[i]=='क' and word[i+1]=='्' and word[i+2]=='ष':\n",
    "                halant_forms.append('क्')\n",
    "                halant_forms.append('ष्')\n",
    "                i+=3\n",
    "                if i<str_len and word[i] in sign_mapping_vowels:\n",
    "                    halant_forms.append(sign_mapping_vowels[word[i]])\n",
    "                    i+=1\n",
    "                else:\n",
    "                    halant_forms.append(halant)\n",
    "                continue\n",
    "            if i+2<str_len and word[i]=='ज' and word[i+1]=='्' and word[i+2]=='ञ':\n",
    "                halant_forms.append('ज्')\n",
    "                halant_forms.append('ञ्')\n",
    "                i+=3\n",
    "                if i<str_len and word[i] in sign_mapping_vowels:\n",
    "                    halant_forms.append(sign_mapping_vowels[word[i]])\n",
    "                    i+=1\n",
    "                else:\n",
    "                    halant_forms.append(halant)\n",
    "                continue\n",
    "            if i+2<str_len and word[i]=='श' and word[i+1]=='्' and word[i+2]=='र':\n",
    "                halant_forms.append('श्')\n",
    "                halant_forms.append('र्')\n",
    "                i+=3\n",
    "                if i<str_len and word[i] in sign_mapping_vowels:\n",
    "                    halant_forms.append(sign_mapping_vowels[word[i]])\n",
    "                    i+=1\n",
    "                else:\n",
    "                    halant_forms.append(halant)\n",
    "                continue\n",
    "\n",
    "            # Check if \n",
    "            halant_forms.append(word[i]+'\\u094D')\n",
    "            i+=1\n",
    "            flag = True\n",
    "            if i<str_len and word[i]=='्':\n",
    "                flag = False\n",
    "                i+=1\n",
    "            elif i<str_len and word[i]=='़':\n",
    "                flag = False\n",
    "                i+=1\n",
    "\n",
    "            if i<str_len and word[i] in sign_mapping_vowels:\n",
    "                halant_forms.append(sign_mapping_vowels[word[i]])\n",
    "                i+=1\n",
    "            elif flag==True:\n",
    "                halant_forms.append(halant)\n",
    "        else:\n",
    "            # If the character is not found, just add it with the halant\n",
    "            # Check i + 1 as well\n",
    "            if word[i] in devanagari_vowels or word[i] in sign_mapping_vowels:\n",
    "                if word[i] == 'अ':\n",
    "                    if i+1<str_len and word[i+1] in sign_mapping_vowels:\n",
    "                        halant_forms.append(sign_mapping_vowels[word[i+1]])\n",
    "                        i+=1\n",
    "                    else:\n",
    "                        halant_forms.append('अ')\n",
    "                    i+=1\n",
    "                else:\n",
    "                    if word[i] in sign_mapping_vowels:\n",
    "                        halant_forms.append(sign_mapping_vowels[word[i]])\n",
    "                    else:\n",
    "                        halant_forms.append(word[i])\n",
    "                    if i+1<str_len and word[i+1] in sign_mapping_vowels:\n",
    "                        halant_forms.append(sign_mapping_vowels[word[i+1]])\n",
    "                        i+=1\n",
    "                    i+=1\n",
    "            else:\n",
    "                halant_forms.append(word[i])\n",
    "                i+=1\n",
    "        \n",
    "    return halant_forms\n",
    "print(do_varn_viched( ' कैंसर ' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['क्', 'ऐ', 'अं', 'स्', 'अ', 'र्', 'अ', ' ']\n",
      "['कैं', 'स', 'र']\n"
     ]
    }
   ],
   "source": [
    "# Given an character array of varn viched it returns list containing syllables\n",
    "def compute_syllable(char_arr):\n",
    "    length = len(char_arr)\n",
    "    i = 0\n",
    "    syll_arr = []\n",
    "    while i<length:\n",
    "        syl = ''\n",
    "        flag = False\n",
    "        if char_arr[i]=='ं':\n",
    "            i+=1\n",
    "            continue\n",
    "        if i<length and char_arr[i] not in devanagari_vowels:\n",
    "            syl+=char_arr[i][0]\n",
    "            i+=1\n",
    "        if i<length and char_arr[i] not in devanagari_vowels:\n",
    "            syl+='्'\n",
    "            syl+=char_arr[i][0]\n",
    "            i+=1\n",
    "        \n",
    "        # vowel encountered\n",
    "        if i<length and char_arr[i]=='अ':\n",
    "            if len(syl)==0:\n",
    "                syl = 'अ'\n",
    "            flag = True\n",
    "        elif len(syl)==0 and char_arr[i] in devanagari_vowels:\n",
    "            syl = char_arr[i]\n",
    "            flag = True\n",
    "        elif i<length and char_arr[i] in sign_mapping_vowels_reversed:\n",
    "            syl+=sign_mapping_vowels_reversed[char_arr[i]]\n",
    "            flag = True\n",
    "            if i+1<length and char_arr[i+1] in sign_mapping_vowels_reversed:\n",
    "                syl+=sign_mapping_vowels_reversed[char_arr[i+1]]\n",
    "                i+=1\n",
    "        i+=1\n",
    "\n",
    "        if flag:\n",
    "            syll_arr.append(syl)\n",
    "    return syll_arr\n",
    "\n",
    "char_arr = do_varn_viched('कैंसर ')\n",
    "print(char_arr)\n",
    "syll_arr = compute_syllable(char_arr)\n",
    "print(syll_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of words to list of list of varn viched\n",
    "def varn_viched_arr(words_list):    \n",
    "    corrected_characters = []\n",
    "    for word in words_list:\n",
    "        sandhi_viched_list = do_varn_viched(word)\n",
    "        corrected_characters.append(sandhi_viched_list)\n",
    "    return corrected_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of words to list of syllables\n",
    "def convert_list_of_words_to_list_of_syllables(words_list):\n",
    "    syllable_final_list = []\n",
    "    for word_list in words_list:\n",
    "        syllable_list = compute_syllable(word_list)\n",
    "        syllable_final_list.append(syllable_list)\n",
    "    return syllable_final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected Words\n",
    "corrected_characters = varn_viched_arr(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32921106\n"
     ]
    }
   ],
   "source": [
    "# Print the counts of characters in original dataset\n",
    "count = 0\n",
    "for line in dataset:\n",
    "    words = line.split()\n",
    "    for word in words:\n",
    "        for char in word:\n",
    "            if char not in ['\\n',' ','।']:\n",
    "                count+=1\n",
    "print(count)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38203957\n"
     ]
    }
   ],
   "source": [
    "# Print the counts of characters in corrected dataset\n",
    "count = 0\n",
    "for list_a in corrected_characters:\n",
    "    for char in list_a:\n",
    "        if char not in ['\\n',' ','।']:\n",
    "            count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucntion to convert sentence into characters\n",
    "def sentence_to_characters(sentence):\n",
    "    varn_viched = do_varn_viched(sentence)\n",
    "    return varn_viched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आ', 'व्', 'ए', 'द्', 'अ', 'न्', 'अ', ' ', 'क्', 'अ', 'र्', 'अ', 'न्', 'ए', ' ', 'क्', 'ई', ' ', 'आ', 'ख्', 'इ', 'र्', 'ई', ' ', 'त्', 'आ', 'र्', 'ई', 'ख्', 'अ', ' ', '3', '1', ' ', 'ज्', 'अ', 'न्', 'अ', 'व्', 'अ', 'र्', 'ई', ',', ' ', '2', '0', '2', '0', ' ', 'ह्', 'ऐ', '।', '\\n', 'इ', 'त्', 'अ', 'न्', 'ई', ' ', 'द्', 'उ', 'आ', ' ', 'क्', 'अ', 'र्', 'अ', ' ', 'द्', 'ओ', ' ', 'ह्', 'अ', 'म्', 'आ', 'र्', 'ए', ' ', 'ल्', 'इ', 'ए', ' ', 'क्', 'इ', ' ', 'ज्', 'इ', 'त्', 'अ', 'न्', 'आ', ' ', 'प्', 'य्', 'आ', 'र्', 'अ', ' ', 'द्', 'उ', 'न्', 'इ', 'य्', 'आ', ' ', 'न्', 'ए', ' ', 'आ', 'प्', 'अ', 'क्', 'ओ', ' ', 'द्', 'इ', 'य्', 'आ', ' ', 'ह्', 'ऐ', ',', ' ', 'ब्', 'अ', 'स्', 'अ', ' ', 'उ', 'त्', 'अ', 'न्', 'आ', ' ', 'ह्', 'ई', ' ', 'ह्', 'अ', 'म्', 'ए', 'अं', ' ', 'भ्', 'ई', ' ', 'म्', 'इ', 'ल्', 'अ', ' ', 'ज्', 'आ', 'ए', '|', '”']\n"
     ]
    }
   ],
   "source": [
    "sentence = '''आवेदन करने की आखिरी तारीख 31 जनवरी, 2020 है।\n",
    "इतनी दुआ कर दो हमारे लिए कि जितना प्यार दुनिया ने आपको दिया है, बस उतना ही हमें भी मिल जाए|”'''\n",
    "\n",
    "print(sentence_to_characters(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unigram Characters\n",
    "characters = {}\n",
    "for list_a in corrected_characters:\n",
    "    for char in list_a:\n",
    "        if char  in ['|','\\”']:\n",
    "            continue\n",
    "        if char in characters:\n",
    "            characters[char] +=1\n",
    "        else:\n",
    "            characters[char] = 1\n",
    "\n",
    "sorted_characters = sorted(characters.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_dict = {key: value for key, value in sorted_characters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "अ 7020567\n",
      "आ 2991109\n",
      "ए 2318442\n",
      "क् 2219964\n",
      "र् 2115649\n",
      "ई 1460305\n",
      "इ 1432973\n",
      "न् 1334448\n",
      "स् 1283708\n",
      "अं 1201207\n",
      "ह् 1133159\n",
      "म् 1053237\n",
      "त् 980066\n",
      "ल् 919917\n",
      "ओ 896588\n",
      "प् 805896\n",
      "य् 752819\n",
      "व् 624743\n",
      "द् 607633\n",
      "उ 587149\n"
     ]
    }
   ],
   "source": [
    "# Top 20 Frequent Unigram Characters\n",
    "count = 0\n",
    "top_twenty_unigram_freq_char = {}\n",
    "for key,value in sorted_dict.items():\n",
    "    top_twenty_unigram_freq_char[key] = value\n",
    "    count+=1\n",
    "    if count==20:\n",
    "        break\n",
    "for key,value in top_twenty_unigram_freq_char.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiGram Frequencies of Characters\n",
    "bigram_frequency_characters = {}\n",
    "i = 0\n",
    "for word_list in corrected_characters:\n",
    "    for i in range(len(word_list)-1):\n",
    "        # Make word using i and i+1\n",
    "        bigram = ''\n",
    "        if word_list[i+1]=='अ':\n",
    "            bigram = word_list[i][0]\n",
    "        elif word_list[i+1] in sign_mapping_vowels_reversed:\n",
    "            bigram = word_list[i][0] + sign_mapping_vowels_reversed[word_list[i+1]]\n",
    "        else:\n",
    "            bigram = word_list[i] + word_list[i+1]\n",
    "        \n",
    "        if bigram in bigram_frequency_characters:\n",
    "            bigram_frequency_characters[bigram]+=1\n",
    "        else:\n",
    "            bigram_frequency_characters[bigram]=1\n",
    "\n",
    "sorted_bigram_frequency_characters = sorted(bigram_frequency_characters.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_bigram_frequency_characters_dict = {key: value for key, value in sorted_bigram_frequency_characters}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र 1173433\n",
      "अर् 781791\n",
      "क 616859\n",
      "स 518746\n",
      "न 515816\n",
      "अन् 427020\n",
      "के 407255\n",
      "प 405637\n",
      "अह् 389898\n",
      "आर् 368494\n",
      "एं 359397\n",
      "त 353264\n",
      "अक् 339718\n",
      "ल 333296\n",
      "ने 328968\n",
      "म 324896\n",
      "का 314857\n",
      "अत् 301202\n",
      "या 297808\n",
      "है 297200\n"
     ]
    }
   ],
   "source": [
    "# Top 20 Bigram Frequency Character\n",
    "top_twenty_bigram_freq_char = {}\n",
    "count = 0\n",
    "for key,value in sorted_bigram_frequency_characters_dict.items():\n",
    "    top_twenty_bigram_freq_char[key] = value\n",
    "    count+=1\n",
    "    if count==20:\n",
    "        break\n",
    "for key,value in top_twenty_bigram_freq_char.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Unigram Syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syllables Unigram\n",
    "syllable_unigram_dict = {}\n",
    "syllable_unigram_list = []\n",
    "for word_list in corrected_characters:\n",
    "    syllable_list = compute_syllable(word_list)\n",
    "    syllable_unigram_list.append(syllable_list)\n",
    "    for syllable in syllable_list:\n",
    "        if syllable in syllable_unigram_dict:\n",
    "            syllable_unigram_dict[syllable] += 1\n",
    "        else:\n",
    "            syllable_unigram_dict[syllable] = 0\n",
    "syllable_unigram_sorted = sorted(syllable_unigram_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "syllable_unigram_sorted_dict = {key: value for key, value in syllable_unigram_sorted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र 1004685\n",
      "क 594953\n",
      "न 501928\n",
      "स 485895\n",
      "के 395613\n",
      "प 387542\n",
      "ल 323591\n",
      "ने 321109\n",
      "त 305293\n",
      "म 290784\n",
      "का 289808\n",
      "ह 278329\n",
      "अ 269457\n",
      "में 259107\n",
      "ब 243811\n",
      "की 233081\n",
      "ग 223716\n",
      "है 215998\n",
      "या 211533\n",
      "से 210345\n"
     ]
    }
   ],
   "source": [
    "# Retriving Top 20 syllable unigram\n",
    "syllable_unigram_top_twenty= {}\n",
    "count = 0\n",
    "for key,value in syllable_unigram_sorted_dict.items():\n",
    "    syllable_unigram_top_twenty[key] = value\n",
    "    count+=1\n",
    "    if count==20:\n",
    "        break\n",
    "for key,value in syllable_unigram_top_twenty.items():\n",
    "    print(key,value )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Top 20 Bigram syllable\n",
    "syllable_bigram_dict = {}\n",
    "for list_a in syllable_unigram_list:\n",
    "    length = len(list_a)\n",
    "    for i in range(length-1):\n",
    "        word = list_a[i] + list_a[i+1]\n",
    "        if word in syllable_bigram_dict:\n",
    "            syllable_bigram_dict[word] += 1\n",
    "        else:\n",
    "            syllable_bigram_dict[word] = 1\n",
    "syllable_bigram_sorted_list = sorted(syllable_bigram_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "syllable_bigram_sorted_dict = {key: value for key, value in syllable_bigram_sorted_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कर 157327\n",
      "और 115321\n",
      "पर 99338\n",
      "इस 81115\n",
      "एक 53423\n",
      "नहीं 47317\n",
      "अप 46640\n",
      "कार 38822\n",
      "किया 36949\n",
      "रने 34462\n",
      "कहा 32110\n",
      "यह 30946\n",
      "गया 30257\n",
      "सर 29754\n",
      "आप 28467\n",
      "उन 27552\n",
      "बाद 27449\n",
      "साथ 26723\n",
      "उस 26091\n",
      "देश 25908\n"
     ]
    }
   ],
   "source": [
    "# Retriving Top 20 Bigram unigram\n",
    "syllable_bigram_top_twenty= {}\n",
    "count = 0\n",
    "for key,value in syllable_bigram_sorted_dict.items():\n",
    "    syllable_bigram_top_twenty[key] = value\n",
    "    count+=1\n",
    "    if count==20:\n",
    "        break\n",
    "for key,value in syllable_bigram_top_twenty.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques 3 : on https://bangla.iitk.ac.in/cs689/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques 4 : Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    " import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove underscore from each string and append to cleaned_strings\n",
    "def clean_strings(strings):\n",
    "    cleaned_strings = []\n",
    "    for string in strings:\n",
    "        cleaned_string = string.replace('▁', '')\n",
    "        cleaned_strings.append(cleaned_string)\n",
    "    return cleaned_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bert_check(tokens):\n",
    "    return [token.lstrip('#').lstrip('▁') for token in tokens]\n",
    "def clean_bert(tokens):\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        # Remove leading '#' and '▁' characters\n",
    "        cleaned_token = token.lstrip('#').lstrip('▁')\n",
    "        # Check if token is not '[UNK]', then add to cleaned tokens\n",
    "        if cleaned_token != '[UNK]':\n",
    "            cleaned_tokens.append(cleaned_token)\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_unigram_frequency(tokens, n=20):\n",
    "    token_frequency = {}\n",
    "    for token in tokens:\n",
    "        token = token.strip()\n",
    "        if token in [' ','','।',',','.']:\n",
    "            continue\n",
    "        if token in token_frequency:\n",
    "            token_frequency[token] += 1\n",
    "        else:\n",
    "            token_frequency[token] = 1\n",
    "    \n",
    "    sorted_token_frequency = sorted(token_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_frequency_dict = {}\n",
    "    count = 0\n",
    "    for key, value in sorted_token_frequency:\n",
    "        top_frequency_dict[key] = value\n",
    "        count += 1\n",
    "        if count == n:\n",
    "            break\n",
    "    \n",
    "    return top_frequency_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_bigram_frequency(tokens, n=20):\n",
    "    tokens_frequency = {}\n",
    "    length = len(tokens)\n",
    "    for i in range(length - 1):\n",
    "        if tokens[i] in [' ','','।',',','.'] or tokens[i+1] in [' ','','।',',','.']:\n",
    "            continue\n",
    "        tokens[i] = tokens[i].strip()\n",
    "        word = tokens[i] + tokens[i + 1]\n",
    "        if word in tokens_frequency:\n",
    "            tokens_frequency[word] += 1\n",
    "        else:\n",
    "            tokens_frequency[word] = 1\n",
    "    \n",
    "    sorted_token_frequency = sorted(tokens_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_frequency_dict = {}\n",
    "    count = 0\n",
    "    for key, value in sorted_token_frequency:\n",
    "        top_frequency_dict[key] = value\n",
    "        count += 1\n",
    "        if count == n:\n",
    "            break\n",
    "    \n",
    "    return top_frequency_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file\n",
    "with open('hi_100.txt', encoding='utf-8') as f:\n",
    "    # Read the content of the file and split it into lines\n",
    "    dataset_2 = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram(Vocab 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: hi_100.txt\n",
      "  input_format: \n",
      "  model_prefix: unigram_model\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: hi_100.txt\n",
      "trainer_interface.cc(378) LOG(WARNING) Found too long line (5994 > 4192).\n",
      "trainer_interface.cc(380) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(381) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 298383 sentences\n",
      "trainer_interface.cc(414) LOG(INFO) Skipped 456 too long sentences.\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=39649689\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9502% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=153\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999502\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 298381 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=18991333\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 395429 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 298381\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 324920\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 324920 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=156332 obj=10.8621 num_tokens=702942 num_tokens/piece=4.49647\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=134610 obj=8.92531 num_tokens=703641 num_tokens/piece=5.22726\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=100903 obj=8.88768 num_tokens=727710 num_tokens/piece=7.21198\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=100760 obj=8.87633 num_tokens=727853 num_tokens/piece=7.22363\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=75563 obj=8.91628 num_tokens=768262 num_tokens/piece=10.1672\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=75557 obj=8.90731 num_tokens=768256 num_tokens/piece=10.1679\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=56667 obj=8.96362 num_tokens=813830 num_tokens/piece=14.3616\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=56667 obj=8.95147 num_tokens=813800 num_tokens/piece=14.3611\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=42500 obj=9.0328 num_tokens=863216 num_tokens/piece=20.311\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=42500 obj=9.0174 num_tokens=863193 num_tokens/piece=20.3104\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=31875 obj=9.12149 num_tokens=915167 num_tokens/piece=28.7111\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=31875 obj=9.10142 num_tokens=915173 num_tokens/piece=28.7113\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=23906 obj=9.23421 num_tokens=969065 num_tokens/piece=40.5365\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=23906 obj=9.21287 num_tokens=969074 num_tokens/piece=40.5369\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=17929 obj=9.37773 num_tokens=1024155 num_tokens/piece=57.1228\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=17929 obj=9.34571 num_tokens=1024169 num_tokens/piece=57.1236\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=13446 obj=9.55358 num_tokens=1079886 num_tokens/piece=80.3128\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=13446 obj=9.51426 num_tokens=1079931 num_tokens/piece=80.3162\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=10084 obj=9.75948 num_tokens=1136993 num_tokens/piece=112.752\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=10084 obj=9.7122 num_tokens=1137021 num_tokens/piece=112.755\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=7563 obj=9.9979 num_tokens=1195057 num_tokens/piece=158.014\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=7563 obj=9.94147 num_tokens=1195156 num_tokens/piece=158.027\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=5672 obj=10.269 num_tokens=1256218 num_tokens/piece=221.477\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=5672 obj=10.2032 num_tokens=1256276 num_tokens/piece=221.487\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=4254 obj=10.57 num_tokens=1322515 num_tokens/piece=310.887\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=4254 obj=10.4928 num_tokens=1322548 num_tokens/piece=310.895\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=3190 obj=10.9027 num_tokens=1393553 num_tokens/piece=436.85\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=3190 obj=10.8123 num_tokens=1393577 num_tokens/piece=436.858\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=2392 obj=11.271 num_tokens=1471177 num_tokens/piece=615.041\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=2392 obj=11.1744 num_tokens=1471222 num_tokens/piece=615.059\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1794 obj=11.6747 num_tokens=1543976 num_tokens/piece=860.633\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1794 obj=11.5641 num_tokens=1543988 num_tokens/piece=860.64\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1345 obj=12.1125 num_tokens=1623113 num_tokens/piece=1206.78\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1345 obj=11.9912 num_tokens=1623111 num_tokens/piece=1206.77\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1100 obj=12.3859 num_tokens=1678184 num_tokens/piece=1525.62\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1100 obj=12.2959 num_tokens=1678185 num_tokens/piece=1525.62\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: unigram_model.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: unigram_model.vocab\n"
     ]
    }
   ],
   "source": [
    "# Train the unigram model\n",
    "spm.SentencePieceTrainer.train(input='hi_100.txt', model_prefix='unigram_model', model_type='unigram', vocab_size=1000)\n",
    "\n",
    "# Load the trained unigram model\n",
    "sp_unigram = spm.SentencePieceProcessor(model_file='unigram_model.model')\n",
    "\n",
    "# Tokenize a sentence\n",
    "unigram_tokens = []\n",
    "for lines in dataset_2:\n",
    "    token_arr = [sp_unigram.encode_as_pieces(lines)]\n",
    "    for token in token_arr:\n",
    "        unigram_tokens.extend(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Tokens\n",
    "unigram_cleaned_tokens = clean_strings(unigram_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र 356914\n",
      "के 348340\n",
      "न 345504\n",
      "ल 289824\n",
      "ा 288472\n",
      "म 249735\n",
      "में 240292\n",
      "की 218069\n",
      "है 215937\n",
      "ने 215735\n",
      "ी 209289\n",
      "क 202594\n",
      "त 183685\n",
      "स 182460\n",
      "े 179021\n",
      "से 176670\n",
      "का 170810\n",
      "को 168213\n",
      "प 168125\n",
      "व 157638\n"
     ]
    }
   ],
   "source": [
    "# Unigram-Token-Unigram-Frequency(1000 vocab)\n",
    "unigram_token_unigram_top_frequency_dict = get_top_unigram_frequency(unigram_cleaned_tokens)\n",
    "for key,value in unigram_token_unigram_top_frequency_dict.items():\n",
    "    print(key,value )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "केलिए 43621\n",
      "हैकि 25130\n",
      "ोंके 21772\n",
      "ोंमें 19868\n",
      "केसाथ 18477\n",
      "तेहैं 17700\n",
      "नेके 17469\n",
      "ोंको 16928\n",
      "ताहै 16193\n",
      "कहाकि 16100\n",
      "केबाद 14510\n",
      "ार 14394\n",
      "ान 14225\n",
      "ोंकी 14197\n",
      "रु 13964\n",
      "नके 13683\n",
      "नेकहा 12585\n",
      "रहाहै 12021\n",
      "ाव 11359\n",
      "गयाहै 11051\n"
     ]
    }
   ],
   "source": [
    "## Unigram-Token-Bigram-Frequency(1000 vocab)\n",
    "unigram_token_bigram_top_frequency_dict = get_top_bigram_frequency(unigram_cleaned_tokens)\n",
    "for key,value in unigram_token_bigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आ', 'व्', 'ए', 'द्', 'अ', 'न्', 'अ', 'क्', 'अ', 'र्']\n"
     ]
    }
   ],
   "source": [
    "# Computing characters of tokens\n",
    "unigram_characters_list = []\n",
    "unigram_character_list_of_list = varn_viched_arr(unigram_cleaned_tokens)\n",
    "for list_arr in unigram_character_list_of_list:\n",
    "    for word in list_arr:\n",
    "        unigram_characters_list.append(word)\n",
    "print(unigram_characters_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "अ 9333159\n",
      "आ 2991109\n",
      "ए 2318442\n",
      "क् 2221101\n",
      "र् 2115631\n",
      "ई 1460305\n",
      "इ 1432973\n",
      "न् 1334418\n",
      "स् 1283708\n",
      "अं 1201207\n",
      "ह् 1133159\n",
      "म् 1053237\n",
      "त् 980066\n",
      "ल् 919917\n",
      "ओ 896588\n",
      "प् 805896\n",
      "य् 753228\n",
      "व् 624743\n",
      "द् 607633\n",
      "उ 587149\n"
     ]
    }
   ],
   "source": [
    "# Unigram-Character-Unigram-Frequency(1000 vocab)\n",
    "unigram_character_unigram_top_frequency_dict = get_top_unigram_frequency(unigram_characters_list)\n",
    "for key,value in unigram_character_unigram_top_frequency_dict.items():\n",
    "    print(key,value )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र्अ 1468923\n",
      "अक् 942367\n",
      "अर् 873378\n",
      "क्अ 721394\n",
      "न्अ 651860\n",
      "स्अ 612819\n",
      "अन् 556237\n",
      "अह् 552074\n",
      "ल्अ 485798\n",
      "प्अ 485241\n",
      "त्अ 480368\n",
      "म्अ 466370\n",
      "अम् 459694\n",
      "अआ 449819\n",
      "अइ 432398\n",
      "आर् 400435\n",
      "क्ए 399017\n",
      "अस् 392628\n",
      "ह्अ 360284\n",
      "एअं 359394\n"
     ]
    }
   ],
   "source": [
    "## Unigram-Character-Bigram-Frequency(1000 vocab)\n",
    "unigram_character_bigram_top_frequency_dict = get_top_bigram_frequency(unigram_characters_list)\n",
    "for key,value in unigram_character_bigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आ', 'वे', 'द', 'न', 'क', 'र', 'ने', 'की', 'आ', 'खि']\n"
     ]
    }
   ],
   "source": [
    "# Unigram-Syllables\n",
    "unigram_syllables_list = []\n",
    "unigram_syllables_list_of_list = convert_list_of_words_to_list_of_syllables(unigram_character_list_of_list)\n",
    "for list_arr in unigram_syllables_list_of_list:\n",
    "    for word in list_arr:\n",
    "        unigram_syllables_list.append(word)\n",
    "print(unigram_syllables_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आ', 'वे', 'द', 'न', 'क', 'र', 'ने', 'की', 'आ', 'खि', 'र', 'ई', 'ता', 'री', 'ख']\n",
      "[['आ'], ['व्', 'ए'], ['द्', 'अ'], ['न्', 'अ'], ['क्', 'अ', 'र्', 'अ', 'न्', 'ए'], ['क्', 'ई'], ['आ', 'ख्', 'इ', 'र्', 'अ'], ['ई'], ['त्', 'आ'], ['र्', 'ई']]\n"
     ]
    }
   ],
   "source": [
    "# Finding\n",
    "print(unigram_syllables_list[:15])\n",
    "print(unigram_character_list_of_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र 1202410\n",
      "क 701410\n",
      "न 643423\n",
      "आ 599606\n",
      "इ 588343\n",
      "स 576723\n",
      "अं 499224\n",
      "ए 487241\n",
      "प 470152\n",
      "ल 469516\n",
      "म 436199\n",
      "त 402488\n",
      "के 393783\n",
      "ह 349626\n",
      "ई 327494\n",
      "ने 323174\n",
      "ग 305862\n",
      "ब 304588\n",
      "ओ 299122\n",
      "का 285232\n"
     ]
    }
   ],
   "source": [
    "# Unigram-Syllables-Unigram-Frequency(1000 vocab)\n",
    "unigram_syllables_unigram_top_frequency_dict = get_top_unigram_frequency(unigram_syllables_list)\n",
    "for key,value in unigram_syllables_unigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कर 185164\n",
      "ओअं 145583\n",
      "और 125868\n",
      "पर 120834\n",
      "इस 106558\n",
      "एअं 77881\n",
      "इत 70510\n",
      "एक 65601\n",
      "इक 61664\n",
      "रइ 60904\n",
      "कार 54400\n",
      "अप 49037\n",
      "आई 47800\n",
      "नहीं 47279\n",
      "केलिे 47080\n",
      "अंग 46577\n",
      "सम 44826\n",
      "रने 43787\n",
      "रआ 42651\n",
      "तक 42443\n"
     ]
    }
   ],
   "source": [
    "## Unigram-Syllables-Bigram-Frequency(1000 vocab)\n",
    "unigram_syllables_bigram_top_frequency_dict = get_top_bigram_frequency(unigram_syllables_list)\n",
    "for key,value in unigram_syllables_bigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SentencePiece - BPE (1000 VocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: hi_100.txt\n",
      "  input_format: \n",
      "  model_prefix: m_bpe\n",
      "  model_type: BPE\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: hi_100.txt\n",
      "trainer_interface.cc(378) LOG(WARNING) Found too long line (5994 > 4192).\n",
      "trainer_interface.cc(380) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(381) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 298383 sentences\n",
      "trainer_interface.cc(414) LOG(INFO) Skipped 456 too long sentences.\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=39649689\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9502% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=153\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999502\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 298381 sentences.\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 298381\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 324920\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1364729 min_freq=1990\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=220725 size=20 all=7449 active=2256 piece=▁ल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=117261 size=40 all=8844 active=3651 piece=िक\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=74160 size=60 all=10391 active=5198 piece=▁थ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58450 size=80 all=12553 active=7360 piece=त्र\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43528 size=100 all=14682 active=9489 piece=▁सं\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=43241 min_freq=4149\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35408 size=120 all=16900 active=3171 piece=▁किया\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28955 size=140 all=18442 active=4713 piece=न्ह\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24411 size=160 all=20405 active=6676 piece=▁राज\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21882 size=180 all=22297 active=8568 piece=▁सर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19406 size=200 all=24144 active=10415 piece=▁चु\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=19305 min_freq=2919\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17837 size=220 all=26375 active=3387 piece=गर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16215 size=240 all=27984 active=4996 piece=▁जी\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14802 size=260 all=29833 active=6845 piece=रो\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13436 size=280 all=31773 active=8785 piece=▁उप\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12360 size=300 all=32981 active=9993 piece=▁पुलिस\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12356 min_freq=1941\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11890 size=320 all=34340 active=2990 piece=▁इसके\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10951 size=340 all=35982 active=4632 piece=चार\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10320 size=360 all=37937 active=6587 piece=▁द्\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9811 size=380 all=39130 active=7780 piece=▁परि\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9445 size=400 all=41055 active=9705 piece=्यों\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9415 min_freq=1429\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8960 size=420 all=42288 active=3222 piece=▁आय\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8386 size=440 all=43529 active=4463 piece=▁दौर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8077 size=460 all=45064 active=5998 piece=▁चल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7730 size=480 all=46422 active=7356 piece=▁सकता\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7442 size=500 all=47949 active=8883 piece=▁चुनाव\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7424 min_freq=1125\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7087 size=520 all=49692 active=4134 piece=▁भारतीय\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6786 size=540 all=51326 active=5768 piece=▁अव\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6635 size=560 all=52202 active=6644 piece=पर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6283 size=580 all=53798 active=8240 piece=▁क्र\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5999 size=600 all=55396 active=9838 piece=भाव\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5982 min_freq=904\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5774 size=620 all=56792 active=4071 piece=▁बो\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5563 size=640 all=58473 active=5752 piece=योग\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5284 size=660 all=59469 active=6748 piece=▁इससे\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5123 size=680 all=60536 active=7815 piece=▁कुमार\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4968 size=700 all=62054 active=9333 piece=ुक\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4952 min_freq=761\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4780 size=720 all=63542 active=4436 piece=वल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4563 size=740 all=64700 active=5594 piece=▁इस्\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4433 size=760 all=65843 active=6737 piece=▁आम\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4313 size=780 all=66568 active=7462 piece=▁आने\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4158 size=800 all=67465 active=8359 piece=▁बंद\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4156 min_freq=659\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4025 size=820 all=68540 active=4417 piece=डे\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3923 size=840 all=69446 active=5323 piece=▁इसमें\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: m_bpe.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: m_bpe.vocab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁आ', 'वे', 'दन', '▁करने', '▁की', '▁आ', 'ख', 'ि', 'री', '▁त', 'ारी', 'ख', '▁3', '1', '▁जन', 'व', 'री', ',', '▁20', '2', '0', '▁है', '।', '▁इ', 'त', 'नी', '▁दु', 'आ', '▁कर', '▁दो', '▁हम', 'ारे', '▁लिए', '▁कि', '▁ज', 'ित', 'ना', '▁प', '्य', 'ार', '▁दु', 'निया', '▁ने', '▁आपको', '▁दिया', '▁है', ',', '▁ब', 'स', '▁उ', 'त', 'ना', '▁ही', '▁हम', 'ें', '▁भी', '▁मिल', '▁जाए', '|', '”', '▁मोदी', '▁सरकार', '▁के', '▁पहले', '▁कार्य', 'क', 'ाल', '▁में', '▁भी', '▁तीन', '▁त', 'ला', 'क', '▁को', '▁लेकर', '▁ब', 'िल', '▁ला', 'या', '▁गया', '▁था', ',', '▁हाल', 'ां', 'कि', '▁त', 'ब', '▁यह', '▁राज्य', 'सभा', '▁में', '▁पास', '▁नहीं', '▁हो', '▁पा', 'या', '▁था', '.', '▁भाजपा', '▁के']\n"
     ]
    }
   ],
   "source": [
    "# Train the BPE model\n",
    "spm.SentencePieceTrainer.train(input='hi_100.txt', model_prefix='m_bpe', model_type='bpe', vocab_size=1000)\n",
    "\n",
    "# Load the trained unigram model\n",
    "sp_bpe_thou = spm.SentencePieceProcessor(model_file='m_bpe.model')\n",
    "\n",
    "# Tokenize a sentence\n",
    "bpe_voc_thou_tokens = []\n",
    "i = 0\n",
    "for lines in dataset_2:\n",
    "    token_arr = [sp_bpe_thou.encode_as_pieces(lines)]\n",
    "    for token in token_arr:\n",
    "        bpe_voc_thou_tokens.extend(token)\n",
    "print(bpe_voc_thou_tokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आ', 'वे', 'दन', 'करने', 'की', 'आ', 'ख', 'ि', 'री', 'त', 'ारी', 'ख', '3', '1', 'जन', 'व', 'री', ',', '20', '2', '0', 'है', '।', 'इ', 'त', 'नी', 'दु', 'आ', 'कर', 'दो', 'हम', 'ारे', 'लिए', 'कि', 'ज', 'ित', 'ना', 'प', '्य', 'ार', 'दु', 'निया', 'ने', 'आपको', 'दिया', 'है', ',', 'ब', 'स', 'उ', 'त', 'ना', 'ही', 'हम', 'ें', 'भी', 'मिल', 'जाए', '|', '”', 'मोदी', 'सरकार', 'के', 'पहले', 'कार्य', 'क', 'ाल', 'में', 'भी', 'तीन', 'त', 'ला', 'क', 'को', 'लेकर', 'ब', 'िल', 'ला', 'या', 'गया', 'था', ',', 'हाल', 'ां', 'कि', 'त', 'ब', 'यह', 'राज्य', 'सभा', 'में', 'पास', 'नहीं', 'हो', 'पा', 'या', 'था', '.', 'भाजपा', 'के']\n"
     ]
    }
   ],
   "source": [
    "# Clean` Tokens\n",
    "bpe_voc_thou_cleaned_tokens = clean_strings(bpe_voc_thou_tokens)\n",
    "print(bpe_voc_thou_cleaned_tokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "के: 364434\n",
      "में: 252765\n",
      "न: 234722\n",
      "की: 227551\n",
      "म: 223876\n",
      "क: 221806\n",
      "है: 215519\n",
      "ने: 209162\n",
      "त: 200426\n",
      "ल: 200164\n",
      "प: 195055\n",
      "स: 187952\n",
      "र: 175155\n",
      "व: 173069\n",
      "से: 171984\n",
      "ज: 171762\n",
      "को: 170953\n",
      "ब: 164575\n",
      "का: 164085\n",
      "द: 158938\n"
     ]
    }
   ],
   "source": [
    "# BPE-Token-Unigram-Frequency(1000 vocab)\n",
    "bpe_voc_thou_unigram_top_frequency_dict = get_top_unigram_frequency(bpe_voc_thou_cleaned_tokens)\n",
    "for key,value in bpe_voc_thou_unigram_top_frequency_dict.items():\n",
    "    print(key + \": \" + str(value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "केलिए: 44391\n",
      "हैकि: 25168\n",
      "केसाथ: 18655\n",
      "ोंके: 18000\n",
      "नेके: 16936\n",
      "कहाकि: 16120\n",
      "ोंमें: 16081\n",
      "तेहैं: 15852\n",
      "केबाद: 15553\n",
      "ोंको: 14276\n",
      "ताहै: 13202\n",
      "नेकहा: 12399\n",
      "रहाहै: 12021\n",
      "ोंकी: 11524\n",
      "गयाहै: 11051\n",
      "रहेहैं: 10180\n",
      "हैऔर: 10112\n",
      "नेकी: 9790\n",
      "वारको: 9214\n",
      "करनेके: 8845\n"
     ]
    }
   ],
   "source": [
    "# BPE-Token-Bigram-Frequency(1000 vocab)\n",
    "bpe_voc_thou_bigram_top_frequency_dict = get_top_bigram_frequency(bpe_voc_thou_cleaned_tokens)\n",
    "for key,value in bpe_voc_thou_bigram_top_frequency_dict.items():\n",
    "    print(key + \": \" + str(value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing characters of tokens\n",
    "bpe_voc_thou_characters_list_of_list = varn_viched_arr(bpe_voc_thou_cleaned_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आ', 'व्', 'ए', 'द्', 'अ', 'न्', 'अ', 'क्', 'अ', 'र्']\n"
     ]
    }
   ],
   "source": [
    "bpe_voc_thou_characters_list = []\n",
    "for list_arr in bpe_voc_thou_characters_list_of_list:\n",
    "    for word in list_arr:\n",
    "        bpe_voc_thou_characters_list.append(word)\n",
    "print(bpe_voc_thou_characters_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "अ 9419952\n",
      "आ 2991109\n",
      "ए 2318442\n",
      "क् 2221101\n",
      "र् 2115631\n",
      "ई 1460305\n",
      "इ 1432973\n",
      "न् 1334418\n",
      "स् 1283708\n",
      "अं 1201207\n",
      "ह् 1133159\n",
      "म् 1053237\n",
      "त् 980066\n",
      "ल् 919917\n",
      "ओ 896588\n",
      "प् 805896\n",
      "य् 753228\n",
      "व् 624743\n",
      "द् 607633\n",
      "उ 587149\n"
     ]
    }
   ],
   "source": [
    "# BPE-Character-Unigram-Frequency(1000 vocab)\n",
    "bpe_voc_thou_character_unigram_top_frequency_dict = get_top_unigram_frequency(bpe_voc_thou_characters_list)\n",
    "for key,value in bpe_voc_thou_character_unigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र्अ 1442644\n",
      "अक् 942367\n",
      "अर् 873378\n",
      "क्अ 731345\n",
      "न्अ 617301\n",
      "स्अ 595092\n",
      "अन् 556237\n",
      "अह् 552074\n",
      "अआ 544503\n",
      "अइ 525262\n",
      "म्अ 512069\n",
      "प्अ 512024\n",
      "ल्अ 461669\n",
      "अम् 459694\n",
      "त्अ 452146\n",
      "आर् 400435\n",
      "क्ए 393587\n",
      "अस् 392628\n",
      "ह्अ 362715\n",
      "एअं 361717\n"
     ]
    }
   ],
   "source": [
    "## BPE-Character-Bigram-Frequency(1000 vocab)\n",
    "bpe_voc_thou_character_bigram_top_frequency_dict = get_top_bigram_frequency(bpe_voc_thou_characters_list)\n",
    "for key,value in bpe_voc_thou_character_bigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPE-Syllables(1000 vocab)\n",
    "bpe_voc_thou_syllables_list = []\n",
    "bpe_voc_thou_syllables_list_of_list = convert_list_of_words_to_list_of_syllables(bpe_voc_thou_characters_list_of_list)\n",
    "for list_arr in bpe_voc_thou_syllables_list_of_list:\n",
    "    for word in list_arr:\n",
    "        bpe_voc_thou_syllables_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र 1198292\n",
      "क 725419\n",
      "आ 693020\n",
      "इ 681207\n",
      "न 611336\n",
      "स 569759\n",
      "प 506804\n",
      "अं 502835\n",
      "म 464701\n",
      "ल 451555\n",
      "ए 448826\n",
      "त 411585\n",
      "के 393586\n",
      "ह 358310\n",
      "ग 331524\n",
      "ने 325957\n",
      "ब 325582\n",
      "ओ 290203\n",
      "ज 287151\n",
      "का 279064\n"
     ]
    }
   ],
   "source": [
    "# BPE-Syllables-Unigram-Frequency(1000 vocab)\n",
    "bpe_voc_thou_syllables_unigram_top_frequency_dict = get_top_unigram_frequency(bpe_voc_thou_syllables_list)\n",
    "for key,value in bpe_voc_thou_syllables_unigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कर 180376\n",
      "और 124488\n",
      "ओअं 117143\n",
      "पर 114745\n",
      "इस 99063\n",
      "एअं 85033\n",
      "इक 72632\n",
      "इत 70900\n",
      "रइ 68602\n",
      "आर 62658\n",
      "कार 62594\n",
      "एक 59766\n",
      "आन 53691\n",
      "अंग 50725\n",
      "अप 50242\n",
      "मआ 48491\n",
      "नहीं 47416\n",
      "आल 47167\n",
      "केलिे 47130\n",
      "सम 46568\n"
     ]
    }
   ],
   "source": [
    "## Bpe-Syllables-Bigram-Frequency(1000 vocab)\n",
    "bpe_voc_thou_syllables_bigram_top_frequency_dict = get_top_bigram_frequency(bpe_voc_thou_syllables_list)\n",
    "for key,value in bpe_voc_thou_syllables_bigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SentencePiece - BPE (2000 VocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: hi_100.txt\n",
      "  input_format: \n",
      "  model_prefix: m_bpe\n",
      "  model_type: BPE\n",
      "  vocab_size: 2000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: hi_100.txt\n",
      "trainer_interface.cc(378) LOG(WARNING) Found too long line (5994 > 4192).\n",
      "trainer_interface.cc(380) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(381) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 298383 sentences\n",
      "trainer_interface.cc(414) LOG(INFO) Skipped 456 too long sentences.\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=39649689\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9502% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=153\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999502\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 298381 sentences.\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 298381\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 324920\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1364729 min_freq=1990\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=220725 size=20 all=7449 active=2256 piece=▁ल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=117261 size=40 all=8844 active=3651 piece=िक\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=74160 size=60 all=10391 active=5198 piece=▁थ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58450 size=80 all=12553 active=7360 piece=त्र\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43528 size=100 all=14682 active=9489 piece=▁सं\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=43241 min_freq=4149\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35408 size=120 all=16900 active=3171 piece=▁किया\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28955 size=140 all=18442 active=4713 piece=न्ह\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24411 size=160 all=20405 active=6676 piece=▁राज\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21882 size=180 all=22297 active=8568 piece=▁सर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19406 size=200 all=24144 active=10415 piece=▁चु\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=19305 min_freq=2919\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17837 size=220 all=26375 active=3387 piece=गर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16215 size=240 all=27984 active=4996 piece=▁जी\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14802 size=260 all=29833 active=6845 piece=रो\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13436 size=280 all=31773 active=8785 piece=▁उप\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12360 size=300 all=32981 active=9993 piece=▁पुलिस\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12356 min_freq=1941\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11890 size=320 all=34340 active=2990 piece=▁इसके\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10951 size=340 all=35982 active=4632 piece=चार\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10320 size=360 all=37937 active=6587 piece=▁द्\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9811 size=380 all=39130 active=7780 piece=▁परि\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9445 size=400 all=41055 active=9705 piece=्यों\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9415 min_freq=1429\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8960 size=420 all=42288 active=3222 piece=▁आय\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8386 size=440 all=43529 active=4463 piece=▁दौर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8077 size=460 all=45064 active=5998 piece=▁चल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7730 size=480 all=46422 active=7356 piece=▁सकता\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7442 size=500 all=47949 active=8883 piece=▁चुनाव\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7424 min_freq=1125\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7087 size=520 all=49692 active=4134 piece=▁भारतीय\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6786 size=540 all=51326 active=5768 piece=▁अव\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6635 size=560 all=52202 active=6644 piece=पर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6283 size=580 all=53798 active=8240 piece=▁क्र\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5999 size=600 all=55396 active=9838 piece=भाव\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5982 min_freq=904\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5774 size=620 all=56792 active=4071 piece=▁बो\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5563 size=640 all=58473 active=5752 piece=योग\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5284 size=660 all=59469 active=6748 piece=▁इससे\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5123 size=680 all=60536 active=7815 piece=▁कुमार\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4968 size=700 all=62054 active=9333 piece=ुक\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4952 min_freq=761\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4780 size=720 all=63542 active=4436 piece=वल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4563 size=740 all=64700 active=5594 piece=▁इस्\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4433 size=760 all=65843 active=6737 piece=▁आम\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4313 size=780 all=66568 active=7462 piece=▁आने\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4158 size=800 all=67465 active=8359 piece=▁बंद\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4156 min_freq=659\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4025 size=820 all=68540 active=4417 piece=डे\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3923 size=840 all=69446 active=5323 piece=▁इसमें\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3812 size=860 all=70222 active=6099 piece=▁मीड\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3706 size=880 all=70861 active=6738 piece=▁आयोज\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3630 size=900 all=72163 active=8040 piece=▁आया\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3630 min_freq=588\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3535 size=920 all=72944 active=4381 piece=फ्त\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3458 size=940 all=73699 active=5136 piece=▁कार्यक्रम\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3379 size=960 all=74936 active=6373 piece=▁कोर्ट\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3316 size=980 all=75695 active=7132 piece=मुख\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3250 size=1000 all=76486 active=7923 piece=▁शर्मा\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3246 min_freq=531\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3160 size=1020 all=77662 active=4994 piece=▁रन\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3105 size=1040 all=78887 active=6219 piece=▁एन\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3044 size=1060 all=79393 active=6725 piece=▁चि\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2958 size=1080 all=80142 active=7474 piece=▁मंद\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2893 size=1100 all=80940 active=8272 piece=▁रात\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2889 min_freq=482\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2825 size=1120 all=81895 active=4993 piece=ल्प\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2778 size=1140 all=83181 active=6279 piece=▁युव\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2726 size=1160 all=84012 active=7110 piece=▁बर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2671 size=1180 all=84712 active=7810 piece=▁महीने\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2630 size=1200 all=86080 active=9178 piece=▁जाएगी\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2629 min_freq=432\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2596 size=1220 all=87303 active=5526 piece=▁गिरफ्त\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2543 size=1240 all=88051 active=6274 piece=▁मौके\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2485 size=1260 all=88922 active=7145 piece=बल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2438 size=1280 all=89712 active=7935 piece=▁यही\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2375 size=1300 all=90315 active=8538 piece=ुन\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2372 min_freq=396\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2323 size=1320 all=91618 active=5666 piece=▁“\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2280 size=1340 all=92486 active=6534 piece=▁लगाया\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2240 size=1360 all=93052 active=7100 piece=▁लगातार\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2200 size=1380 all=93957 active=8005 piece=▁शिकायत\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2169 size=1400 all=94750 active=8798 piece=▁भग\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2168 min_freq=366\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2129 size=1420 all=95553 active=5514 piece=▁रखने\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2098 size=1440 all=96282 active=6243 piece=▁देखने\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2057 size=1460 all=97045 active=7006 piece=▁लिखा\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2040 size=1480 all=98031 active=7992 piece=▁लगता\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1995 size=1500 all=98582 active=8543 piece=▁सामान\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1993 min_freq=343\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1968 size=1520 all=99572 active=5914 piece=बंधन\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1942 size=1540 all=100273 active=6615 piece=गम\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1923 size=1560 all=100957 active=7299 piece=▁छोट\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1888 size=1580 all=101747 active=8089 piece=▁शो\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1856 size=1600 all=102552 active=8894 piece=▁पेट\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1855 min_freq=318\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1835 size=1620 all=103434 active=5975 piece=▁नरेंद्र\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1804 size=1640 all=104398 active=6939 piece=खंड\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1780 size=1660 all=105152 active=7693 piece=न्‍\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1765 size=1680 all=105822 active=8363 piece=▁अंग\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1743 size=1700 all=106312 active=8853 piece=▁गौर\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1736 min_freq=299\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1720 size=1720 all=106835 active=5816 piece=▁चाल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1699 size=1740 all=107184 active=6165 piece=▁नागरिक\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1667 size=1760 all=107998 active=6979 piece=▁राय\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1646 size=1780 all=108820 active=7801 piece=▁D\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1631 size=1800 all=109220 active=8201 piece=क्रिया\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1630 min_freq=284\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1611 size=1820 all=110123 active=6329 piece=▁सहयोग\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1593 size=1840 all=110928 active=7134 piece=▁बनी\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: m_bpe.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: m_bpe.vocab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3769\n"
     ]
    }
   ],
   "source": [
    "# Train the BPE model\n",
    "spm.SentencePieceTrainer.train(input='hi_100.txt', model_prefix='m_bpe', model_type='bpe', vocab_size=2000)\n",
    "\n",
    "# Load the trained unigram model\n",
    "sp_bpe_two_thou = spm.SentencePieceProcessor(model_file='m_bpe.model')\n",
    "\n",
    "# Tokenize a sentence\n",
    "bpe_voc_two_thou_tokens = []\n",
    "i = 0\n",
    "for lines in dataset_2:\n",
    "    token_arr = [sp_bpe_two_thou.encode_as_pieces(lines)]\n",
    "    for token in token_arr:\n",
    "        bpe_voc_two_thou_tokens.extend(token)\n",
    "print(len(set(bpe_voc_two_thou_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आ', 'वेदन', 'करने', 'की', 'आख', 'ि', 'री', 'त', 'ारी', 'ख', '3', '1', 'जनवरी', ',', '20', '20', 'है', '।', 'इत', 'नी', 'दु', 'आ', 'कर', 'दो', 'हमारे', 'लिए', 'कि', 'ज', 'ित', 'ना', 'प', '्य', 'ार', 'दुनिया', 'ने', 'आपको', 'दिया', 'है', ',', 'बस', 'उ', 'त', 'ना', 'ही', 'हमें', 'भी', 'मिल', 'जाए', '|', '”', 'मोदी', 'सरकार', 'के', 'पहले', 'कार्य', 'काल', 'में', 'भी', 'तीन', 'त', 'ला', 'क', 'को', 'लेकर', 'बिल', 'ला', 'या', 'गया', 'था', ',', 'हालांकि', 'तब', 'यह', 'राज्य', 'सभा', 'में', 'पास', 'नहीं', 'हो', 'पा', 'या', 'था', '.', 'भाजपा', 'के', 'दिव', 'ंग', 'त', 'नेता', 'प्र', 'मो', 'द', 'महा', 'जन', 'की', 'बे', 'टी', 'पू', 'न', 'म']\n"
     ]
    }
   ],
   "source": [
    "# Clean Tokens\n",
    "bpe_voc_two_thou_tokens_cleaned = clean_strings(bpe_voc_two_thou_tokens)\n",
    "print(bpe_voc_two_thou_tokens_cleaned[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "के: 344230\n",
      "में: 245494\n",
      "है: 215519\n",
      "की: 214647\n",
      "ने: 178508\n",
      "को: 164642\n",
      "से: 161960\n",
      "का: 147974\n",
      "क: 133331\n",
      "न: 124503\n",
      "और: 115365\n",
      "म: 114131\n",
      "स: 111941\n",
      "पर: 105525\n",
      "प: 99336\n",
      "व: 96389\n",
      "ल: 95954\n",
      "त: 94389\n",
      "कि: 92995\n",
      "द: 90949\n"
     ]
    }
   ],
   "source": [
    "# BPE-Token-Unigram-Frequency(2000 vocab)\n",
    "bpe_voc_two_thou_unigram_top_frequency_dict = get_top_unigram_frequency(bpe_voc_two_thou_tokens_cleaned)\n",
    "for key,value in bpe_voc_two_thou_unigram_top_frequency_dict.items():\n",
    "    print(key + \": \" + str(value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "केलिए: 43665\n",
      "हैकि: 25114\n",
      "केसाथ: 18477\n",
      "कहाकि: 16116\n",
      "केबाद: 14522\n",
      "ोंके: 13496\n",
      "ोंमें: 13054\n",
      "नेकहा: 12055\n",
      "रहाहै: 12021\n",
      "नेके: 11820\n",
      "ताहै: 11124\n",
      "गयाहै: 11051\n",
      "रहेहैं: 10180\n",
      "ोंको: 10138\n",
      "हैऔर: 10112\n",
      "करनेके: 8845\n",
      "रहीहै: 8754\n",
      "ोंकी: 8376\n",
      "तेहैं: 8120\n",
      "जाताहै: 7337\n"
     ]
    }
   ],
   "source": [
    "# BPE-Token-Bigram-Frequency(2000 vocab)\n",
    "bpe_voc_two_thou_bigram_top_frequency_dict = get_top_bigram_frequency(bpe_voc_two_thou_tokens_cleaned)\n",
    "for key,value in bpe_voc_two_thou_bigram_top_frequency_dict.items():\n",
    "    print(key + \": \" + str(value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing characters of tokens\n",
    "bpe_voc_two_thou_characters_list_of_list = varn_viched_arr(bpe_voc_two_thou_tokens_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आ', 'व्', 'ए', 'द्', 'अ', 'न्', 'अ', 'क्', 'अ', 'र्']\n"
     ]
    }
   ],
   "source": [
    "# Convert list of list to list\n",
    "bpe_voc_two_thou_characters_list = []\n",
    "for list_arr in bpe_voc_two_thou_characters_list_of_list:\n",
    "    for word in list_arr:\n",
    "        bpe_voc_two_thou_characters_list.append(word)\n",
    "print(bpe_voc_two_thou_characters_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "अ 8564775\n",
      "आ 2991109\n",
      "ए 2318442\n",
      "क् 2221101\n",
      "र् 2115631\n",
      "ई 1460305\n",
      "इ 1432973\n",
      "न् 1334418\n",
      "स् 1283708\n",
      "अं 1201207\n",
      "ह् 1133159\n",
      "म् 1053237\n",
      "त् 980066\n",
      "ल् 919917\n",
      "ओ 896588\n",
      "प् 805896\n",
      "य् 753228\n",
      "व् 624743\n",
      "द् 607633\n",
      "उ 587149\n"
     ]
    }
   ],
   "source": [
    "# BPE-Character-Unigram-Frequency(2000 vocab)\n",
    "bpe_voc_two_thou_character_unigram_top_frequency_dict = get_top_unigram_frequency(bpe_voc_two_thou_characters_list)\n",
    "for key,value in bpe_voc_two_thou_character_unigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र्अ 1360454\n",
      "अक् 942367\n",
      "अर् 873378\n",
      "क्अ 679341\n",
      "न्अ 589654\n",
      "स्अ 579577\n",
      "अन् 556237\n",
      "अह् 552074\n",
      "प्अ 465789\n",
      "अम् 459694\n",
      "म्अ 431810\n",
      "ल्अ 427629\n",
      "त्अ 409022\n",
      "क्ए 403035\n",
      "आर् 400435\n",
      "अस् 392628\n",
      "अइ 362517\n",
      "अआ 362365\n",
      "एअं 362008\n",
      "अत् 349069\n"
     ]
    }
   ],
   "source": [
    "## BPE-Character-Bigram-Frequency(2000 vocab)\n",
    "bpe_voc_two_thou_character_bigram_top_frequency_dict = get_top_bigram_frequency(bpe_voc_two_thou_characters_list)\n",
    "for key,value in bpe_voc_two_thou_character_bigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPE-Syllables(2000 vocab)\n",
    "bpe_voc_two_thou_syllables_list = []\n",
    "bpe_voc_two_thou_syllables_list_of_list = convert_list_of_words_to_list_of_syllables(bpe_voc_two_thou_characters_list_of_list)\n",
    "for list_arr in bpe_voc_two_thou_syllables_list_of_list:\n",
    "    for word in list_arr:\n",
    "        bpe_voc_two_thou_syllables_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र 1132994\n",
      "क 667538\n",
      "न 583689\n",
      "स 552511\n",
      "इ 516691\n",
      "आ 506246\n",
      "प 452203\n",
      "ल 415471\n",
      "अं 403037\n",
      "के 397632\n",
      "म 384884\n",
      "त 364425\n",
      "ह 334884\n",
      "ने 325957\n",
      "ए 325951\n",
      "ब 297040\n",
      "का 296060\n",
      "ग 291416\n",
      "में 259459\n",
      "अ 250278\n"
     ]
    }
   ],
   "source": [
    "# BPE-Syllables-Unigram-Frequency(1000 vocab)\n",
    "bpe_voc_two_thou_syllables_unigram_top_frequency_dict = get_top_unigram_frequency(bpe_voc_two_thou_syllables_list)\n",
    "for key,value in bpe_voc_two_thou_syllables_unigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कर 173287\n",
      "और 119789\n",
      "पर 109118\n",
      "इस 96600\n",
      "ओअं 90439\n",
      "एअं 62042\n",
      "एक 58249\n",
      "कार 52824\n",
      "अप 49679\n",
      "इक 48971\n",
      "रइ 48244\n",
      "इत 47568\n",
      "नहीं 47416\n",
      "केलिे 47130\n",
      "रने 44141\n",
      "तक 42221\n",
      "आर 41309\n",
      "रआ 38832\n",
      "सम 38057\n",
      "किया 36694\n"
     ]
    }
   ],
   "source": [
    "## Bpe-Syllables-Bigram-Frequency(1000 vocab)\n",
    "bpe_voc_two_thou_syllables_bigram_top_frequency_dict = get_top_bigram_frequency(bpe_voc_two_thou_syllables_list)\n",
    "for key,value in bpe_voc_two_thou_syllables_bigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mBert (Max Length 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load File\n",
    "with open(\"hi_100.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 19:02:50.013641: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-17 19:02:52.858967: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast, TFBertModel\n",
    "tokenizer_thou = BertTokenizerFast.from_pretrained('bert-base-multilingual-cased',max_length=1000,truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (16437918 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "mBert_thou_unigram_token = tokenizer_thou.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Output\n",
    "mBert_thou_unigram_token_cleaned = clean_bert(mBert_thou_unigram_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "के: 346811\n",
      "स: 328616\n",
      "प: 309011\n",
      "म: 304412\n",
      "र: 299531\n",
      "ब: 255223\n",
      "में: 246128\n",
      "न: 234436\n",
      "है: 215589\n",
      "की: 212670\n",
      "ा: 201872\n",
      "क: 189855\n",
      "ल: 185250\n",
      "को: 173906\n",
      "ी: 171486\n",
      "ने: 171432\n",
      "से: 165253\n",
      "का: 164386\n",
      "ज: 148861\n",
      "अ: 133090\n"
     ]
    }
   ],
   "source": [
    "# mBert-Token-Unigram-Frequency(1000 max-length)\n",
    "mBert_thou_unigram_top_frequency_dict = get_top_unigram_frequency(mBert_thou_unigram_token_cleaned)\n",
    "for key,value in mBert_thou_unigram_top_frequency_dict.items():\n",
    "    print(key + \": \" + str(value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "केलिए: 44090\n",
      "प्र: 38058\n",
      "आप: 26585\n",
      "हैकि: 25191\n",
      "केसाथ: 18553\n",
      "मु: 18040\n",
      "ोंके: 17041\n",
      "सम: 16799\n",
      "सु: 16294\n",
      "कहाकि: 16126\n",
      "बता: 15906\n",
      "ोंमें: 15332\n",
      "सा: 15209\n",
      "जर: 14549\n",
      "केबाद: 14486\n",
      "पुल: 13840\n",
      "ोंको: 13719\n",
      "मो: 13671\n",
      "मौ: 13171\n",
      "ुलिस: 12630\n"
     ]
    }
   ],
   "source": [
    "# mBert-Token-Bigram-Frequency(1000 max-length)\n",
    "mBert_thou_bigram_top_frequency_dict = get_top_bigram_frequency(mBert_thou_unigram_token_cleaned)\n",
    "for key,value in mBert_thou_bigram_top_frequency_dict.items():\n",
    "    print(key + \": \" + str(value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing characters of tokens\n",
    "mbert_thou_characters_list_of_list = varn_viched_arr(mBert_thou_unigram_token_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आ', 'व्', 'ए', 'द्', 'अ', 'न्', 'अ', 'क्', 'अ', 'र्']\n"
     ]
    }
   ],
   "source": [
    "# Convert list of list to list\n",
    "mbert_thou_characters_list = []\n",
    "for list_arr in mbert_thou_characters_list_of_list:\n",
    "    for word in list_arr:\n",
    "        mbert_thou_characters_list.append(word)\n",
    "print(mbert_thou_characters_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "अ 10121755\n",
      "आ 2973003\n",
      "ए 2308471\n",
      "क् 2212682\n",
      "र् 2107728\n",
      "ई 1450096\n",
      "इ 1427101\n",
      "न् 1329848\n",
      "स् 1280401\n",
      "अं 1196767\n",
      "ह् 1131668\n",
      "म् 1050470\n",
      "त् 974128\n",
      "ल् 915089\n",
      "ओ 888539\n",
      "प् 798813\n",
      "य् 750641\n",
      "् 664890\n",
      "व् 622964\n",
      "द् 605658\n"
     ]
    }
   ],
   "source": [
    "# mBert-Character-Unigram-Frequency(1000 max_length)\n",
    "mbert_thou_character_unigram_top_frequency_dict = get_top_unigram_frequency(mbert_thou_characters_list)\n",
    "for key,value in mbert_thou_character_unigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र्अ 1627178\n",
      "अक् 943340\n",
      "अर् 870624\n",
      "क्अ 772041\n",
      "स्अ 762023\n",
      "न्अ 732172\n",
      "अ् 662419\n",
      "प्अ 604534\n",
      "अआ 561134\n",
      "अइ 559192\n",
      "अन् 556068\n",
      "अह् 552583\n",
      "म्अ 540027\n",
      "ल्अ 494169\n",
      "त्अ 492672\n",
      "अम् 460084\n",
      "आर् 399528\n",
      "क्ए 396789\n",
      "अस् 393007\n",
      "ब्अ 376012\n"
     ]
    }
   ],
   "source": [
    "## mBert-Character-Bigram-Frequency(1000 max_length)\n",
    "mbert_thou_character_bigram_top_frequency_dict = get_top_bigram_frequency(mbert_thou_characters_list)\n",
    "for key,value in mbert_thou_character_bigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mBert-Syllables(1000 max-length)\n",
    "mBert_thou_syllables_list_of_list = convert_list_of_words_to_list_of_syllables(mbert_thou_characters_list_of_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mBert Converting list of list to list\n",
    "mBert_thou_syllables_list = []\n",
    "for list_arr in mBert_thou_syllables_list_of_list:\n",
    "    for word in list_arr:\n",
    "        mBert_thou_syllables_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र 1411258\n",
      "क 741686\n",
      "स 722828\n",
      "न 712665\n",
      "इ 711151\n",
      "आ 702699\n",
      "प 599667\n",
      "अं 551442\n",
      "म 501312\n",
      "ए 482219\n",
      "ल 462468\n",
      "त 419911\n",
      "उ 408116\n",
      "के 391488\n",
      "ब 375316\n",
      "ह 351739\n",
      "ग 340226\n",
      "ओ 332811\n",
      "ई 305640\n",
      "ने 304620\n"
     ]
    }
   ],
   "source": [
    "# mBert-Syllables-Unigram-Frequency(1000 max_length)\n",
    "mBert_thou_syllables_unigram_top_frequency_dict = get_top_unigram_frequency(mBert_thou_syllables_list)\n",
    "for key,value in mBert_thou_syllables_unigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कर 212943\n",
      "पर 129133\n",
      "और 125331\n",
      "इस 121154\n",
      "ओअं 117274\n",
      "रआ 92539\n",
      "एक 71267\n",
      "रइ 69564\n",
      "नइ 61665\n",
      "अंग 58065\n",
      "कार 55917\n",
      "आर 53335\n",
      "एअं 51794\n",
      "रए 50331\n",
      "अप 48818\n",
      "इअं 47746\n",
      "नहीं 47362\n",
      "केलिे 47138\n",
      "नआ 47031\n",
      "मइ 46164\n"
     ]
    }
   ],
   "source": [
    "## mBert-Syllables-Bigram-Frequency(1000 max-length)\n",
    "mBert_thou_syllables_bigram_top_frequency_dict = get_top_bigram_frequency(mBert_thou_syllables_list)\n",
    "for key,value in mBert_thou_syllables_bigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mBert (Max Length 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "tokenizer_two_thou = BertTokenizer.from_pretrained('bert-base-multilingual-cased',model_max_length=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize using mBert (max length 2000)\n",
    "mBert_two_thou_unigram_token = tokenizer_two_thou.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Output\n",
    "mBert_two_thou_unigram_token_cleaned = clean_bert(mBert_two_thou_unigram_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "के: 346811\n",
      "स: 328616\n",
      "प: 309011\n",
      "म: 304412\n",
      "र: 299531\n",
      "ब: 255223\n",
      "में: 246128\n",
      "न: 234436\n",
      "है: 215589\n",
      "की: 212670\n",
      "ा: 201872\n",
      "क: 189855\n",
      "ल: 185250\n",
      "को: 173906\n",
      "ी: 171486\n",
      "ने: 171432\n",
      "से: 165253\n",
      "का: 164386\n",
      "ज: 148861\n",
      "अ: 133090\n"
     ]
    }
   ],
   "source": [
    "# mBert-Token-Unigram-Frequency(2000 max-length)\n",
    "mBert_two_thou_unigram_top_frequency_dict = get_top_unigram_frequency(mBert_two_thou_unigram_token_cleaned)\n",
    "for key,value in mBert_two_thou_unigram_top_frequency_dict.items():\n",
    "    print(key + \": \" + str(value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "केलिए: 44090\n",
      "प्र: 38058\n",
      "आप: 26585\n",
      "हैकि: 25191\n",
      "केसाथ: 18553\n",
      "मु: 18040\n",
      "ोंके: 17041\n",
      "सम: 16799\n",
      "सु: 16294\n",
      "कहाकि: 16126\n",
      "बता: 15906\n",
      "ोंमें: 15332\n",
      "सा: 15209\n",
      "जर: 14549\n",
      "केबाद: 14486\n",
      "पुल: 13840\n",
      "ोंको: 13719\n",
      "मो: 13671\n",
      "मौ: 13171\n",
      "ुलिस: 12630\n"
     ]
    }
   ],
   "source": [
    "# mBert-Token-Bigram-Frequency(2000 max-length)\n",
    "mBert_two_thou_bigram_top_frequency_dict = get_top_bigram_frequency(mBert_two_thou_unigram_token_cleaned)\n",
    "for key,value in mBert_two_thou_bigram_top_frequency_dict.items():\n",
    "    print(key + \": \" + str(value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing characters of tokens\n",
    "mbert_two_thou_characters_list_of_list = varn_viched_arr(mBert_two_thou_unigram_token_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आ', 'व्', 'ए', 'द्', 'अ', 'न्', 'अ', 'क्', 'अ', 'र्']\n"
     ]
    }
   ],
   "source": [
    "# Convert list of list to list\n",
    "mbert_two_thou_characters_list = []\n",
    "for list_arr in mbert_two_thou_characters_list_of_list:\n",
    "    for word in list_arr:\n",
    "        mbert_two_thou_characters_list.append(word)\n",
    "print(mbert_two_thou_characters_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "अ 10121755\n",
      "आ 2973003\n",
      "ए 2308471\n",
      "क् 2212682\n",
      "र् 2107728\n",
      "ई 1450096\n",
      "इ 1427101\n",
      "न् 1329848\n",
      "स् 1280401\n",
      "अं 1196767\n",
      "ह् 1131668\n",
      "म् 1050470\n",
      "त् 974128\n",
      "ल् 915089\n",
      "ओ 888539\n",
      "प् 798813\n",
      "य् 750641\n",
      "् 664890\n",
      "व् 622964\n",
      "द् 605658\n"
     ]
    }
   ],
   "source": [
    "# mBert-Character-Unigram-Frequency(2000 max_length)\n",
    "mbert_two_thou_character_unigram_top_frequency_dict = get_top_unigram_frequency(mbert_two_thou_characters_list)\n",
    "for key,value in mbert_two_thou_character_unigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र्अ 1627178\n",
      "अक् 943340\n",
      "अर् 870624\n",
      "क्अ 772041\n",
      "स्अ 762023\n",
      "न्अ 732172\n",
      "अ् 662419\n",
      "प्अ 604534\n",
      "अआ 561134\n",
      "अइ 559192\n",
      "अन् 556068\n",
      "अह् 552583\n",
      "म्अ 540027\n",
      "ल्अ 494169\n",
      "त्अ 492672\n",
      "अम् 460084\n",
      "आर् 399528\n",
      "क्ए 396789\n",
      "अस् 393007\n",
      "ब्अ 376012\n"
     ]
    }
   ],
   "source": [
    "## mBert-Character-Bigram-Frequency(2000 max_length)\n",
    "mbert_two_thou_character_bigram_top_frequency_dict = get_top_bigram_frequency(mbert_two_thou_characters_list)\n",
    "for key,value in mbert_two_thou_character_bigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mBert-Syllables(1000 max-length)\n",
    "mBert_two_thou_syllables_list_of_list = convert_list_of_words_to_list_of_syllables(mbert_two_thou_characters_list_of_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mBert Converting list of list to list\n",
    "mBert_two_thou_syllables_list = []\n",
    "for list_arr in mBert_two_thou_syllables_list_of_list:\n",
    "    for word in list_arr:\n",
    "        mBert_two_thou_syllables_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र 1411258\n",
      "क 741686\n",
      "स 722828\n",
      "न 712665\n",
      "इ 711151\n",
      "आ 702699\n",
      "प 599667\n",
      "अं 551442\n",
      "म 501312\n",
      "ए 482219\n",
      "ल 462468\n",
      "त 419911\n",
      "उ 408116\n",
      "के 391488\n",
      "ब 375316\n",
      "ह 351739\n",
      "ग 340226\n",
      "ओ 332811\n",
      "ई 305640\n",
      "ने 304620\n"
     ]
    }
   ],
   "source": [
    "# mBert-Syllables-Unigram-Frequency(1000 max_length)\n",
    "mBert_two_thou_syllables_unigram_top_frequency_dict = get_top_unigram_frequency(mBert_two_thou_syllables_list)\n",
    "for key,value in mBert_two_thou_syllables_unigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कर 212943\n",
      "पर 129133\n",
      "और 125331\n",
      "इस 121154\n",
      "ओअं 117274\n",
      "रआ 92539\n",
      "एक 71267\n",
      "रइ 69564\n",
      "नइ 61665\n",
      "अंग 58065\n",
      "कार 55917\n",
      "आर 53335\n",
      "एअं 51794\n",
      "रए 50331\n",
      "अप 48818\n",
      "इअं 47746\n",
      "नहीं 47362\n",
      "केलिे 47138\n",
      "नआ 47031\n",
      "मइ 46164\n"
     ]
    }
   ],
   "source": [
    "## mBert-Syllables-Bigram-Frequency(1000 max-length)\n",
    "mBert_two_thou_syllables_bigram_top_frequency_dict = get_top_bigram_frequency(mBert_two_thou_syllables_list)\n",
    "for key,value in mBert_two_thou_syllables_bigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IndicBERT (max_length 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load File\n",
    "with open(\"hi_100.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "indic_tokenizer_thou = AutoTokenizer.from_pretrained('ai4bharat/indic-bert',use_fast=False,verbose=True,max_length = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization using indicBert\n",
    "indicBert_thou_unigram_token = indic_tokenizer_thou.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Output\n",
    "indicBert_thou_unigram_cleaned = clean_bert(indicBert_thou_unigram_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "के: 328517\n",
      "में: 241386\n",
      "है: 214413\n",
      "की: 198743\n",
      "पर: 186484\n",
      "को: 153868\n",
      "से: 143492\n",
      "ने: 127227\n",
      "का: 117758\n",
      "और: 115482\n",
      "स: 88385\n",
      "कि: 86752\n",
      "य: 80503\n",
      "हैं: 80315\n",
      "कर: 72655\n",
      "भी: 65969\n",
      "ष: 65536\n",
      "ों: 58313\n",
      "एक: 57250\n",
      "क: 55157\n"
     ]
    }
   ],
   "source": [
    "# indicBert-Token-Unigram-Frequency(1000 max-length)\n",
    "indicBert_thou_unigram_top_frequency_dict = get_top_unigram_frequency(indicBert_thou_unigram_cleaned)\n",
    "for key,value in indicBert_thou_unigram_top_frequency_dict.items():\n",
    "    print(key + \": \" + str(value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "केलिए: 43496\n",
      "हैकि: 25058\n",
      "केसाथ: 18312\n",
      "होंने: 17726\n",
      "कहाकि: 16129\n",
      "नेकहा: 15563\n",
      "कष: 14580\n",
      "केबाद: 14411\n",
      "मंतरी: 12670\n",
      "रहाहै: 12020\n",
      "गयाहै: 11061\n",
      "ोंके: 10787\n",
      "उनहों: 10532\n",
      "कारय: 10251\n",
      "रहेहैं: 10178\n",
      "हैऔर: 10127\n",
      "राष: 9720\n",
      "दवारा: 9372\n",
      "उनहें: 9144\n",
      "ोंको: 9000\n"
     ]
    }
   ],
   "source": [
    "# indicBert-Token-Bigram-Frequency(1000 max-length)\n",
    "indic_thou_bigram_top_frequency_dict = get_top_bigram_frequency(indicBert_thou_unigram_cleaned)\n",
    "for key,value in indic_thou_bigram_top_frequency_dict.items():\n",
    "    print(key + \": \" + str(value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing characters of tokens\n",
    "indic_thou_characters_list_of_list = varn_viched_arr(indicBert_thou_unigram_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आ', 'व्', 'ए', 'द्', 'अ', 'न्', 'अ', 'क्', 'अ', 'र्']\n"
     ]
    }
   ],
   "source": [
    "# Convert list of list to list\n",
    "indic_thou_characters_list = []\n",
    "for list_arr in indic_thou_characters_list_of_list:\n",
    "    for word in list_arr:\n",
    "        indic_thou_characters_list.append(word)\n",
    "print(indic_thou_characters_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "अ 9021271\n",
      "आ 2991109\n",
      "ए 2318442\n",
      "क् 2221101\n",
      "र् 2115912\n",
      "ई 1460305\n",
      "इ 1432973\n",
      "न् 1335232\n",
      "स् 1283708\n",
      "अं 1201207\n",
      "ह् 1133159\n",
      "म् 1053237\n",
      "त् 980066\n",
      "ल् 919917\n",
      "ओ 896588\n",
      "प् 805896\n",
      "य् 753228\n",
      "व् 624743\n",
      "द् 607633\n",
      "उ 587149\n"
     ]
    }
   ],
   "source": [
    "# indicBert-Character-Unigram-Frequency(1000 max_length)\n",
    "indic_thou_character_unigram_top_frequency_dict = get_top_unigram_frequency(indic_thou_characters_list)\n",
    "for key,value in indic_thou_character_unigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र्अ 1525832\n",
      "अर् 1206308\n",
      "अक् 997512\n",
      "क्अ 805473\n",
      "स्अ 702627\n",
      "न्अ 635322\n",
      "अह् 591176\n",
      "अन् 585022\n",
      "प्अ 555241\n",
      "अम् 531558\n",
      "त्अ 522037\n",
      "अत् 471335\n",
      "अस् 438049\n",
      "ल्अ 427792\n",
      "क्ए 403275\n",
      "आर् 400534\n",
      "म्अ 384518\n",
      "एअं 363519\n",
      "अल् 342759\n",
      "अय् 341016\n"
     ]
    }
   ],
   "source": [
    "## indicBert-Character-Bigram-Frequency(1000 max_length)\n",
    "indic_thou_character_bigram_top_frequency_dict = get_top_bigram_frequency(indic_thou_characters_list)\n",
    "for key,value in indic_thou_character_bigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicBert-Syllables(1000 max-length)\n",
    "indic_thou_syllables_list_of_list = convert_list_of_words_to_list_of_syllables(indic_thou_characters_list_of_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicBert Converting list of list to list\n",
    "indic_thou_syllables_list = []\n",
    "for list_arr in indic_thou_syllables_list_of_list:\n",
    "    for word in list_arr:\n",
    "        indic_thou_syllables_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र 1520979\n",
      "क 801973\n",
      "स 701122\n",
      "न 631966\n",
      "प 553528\n",
      "त 521976\n",
      "ल 423355\n",
      "के 401315\n",
      "म 382930\n",
      "ने 322671\n",
      "आ 317459\n",
      "य 306052\n",
      "का 295482\n",
      "ह 293243\n",
      "ब 279336\n",
      "ग 277979\n",
      "इ 274450\n",
      "या 271454\n",
      "व 266429\n",
      "ज 263566\n"
     ]
    }
   ],
   "source": [
    "# indicBert-Syllables-Unigram-Frequency(1000 max_length)\n",
    "indic_thou_syllables_unigram_top_frequency_dict = get_top_unigram_frequency(indic_thou_syllables_list)\n",
    "for key,value in indic_thou_syllables_unigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "पर 221155\n",
      "कर 197336\n",
      "और 116389\n",
      "इस 94077\n",
      "तर 78366\n",
      "कार 65862\n",
      "ओअं 64653\n",
      "एक 64396\n",
      "उन 57364\n",
      "रक 48988\n",
      "नहीं 48049\n",
      "अप 47798\n",
      "केलिे 47128\n",
      "तक 46834\n",
      "दर 45558\n",
      "रआ 45534\n",
      "रने 44746\n",
      "रत 43364\n",
      "कष 43095\n",
      "टर 42554\n"
     ]
    }
   ],
   "source": [
    "## indic-Syllables-Bigram-Frequency(1000 max-length)\n",
    "indic_thou_syllables_bigram_top_frequency_dict = get_top_bigram_frequency(indic_thou_syllables_list)\n",
    "for key,value in indic_thou_syllables_bigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IndicBERT (max_length 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "indic_tokenizer_two_thou = AutoTokenizer.from_pretrained('ai4bharat/indic-bert',use_fast=False,verbose=True,max_length = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization using indicBert\n",
    "indicBert_two_thou_unigram_token = indic_tokenizer_two_thou.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Output\n",
    "indicBert_two_thou_unigram_cleaned = clean_bert(indicBert_two_thou_unigram_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "के: 328517\n",
      "में: 241386\n",
      "है: 214413\n",
      "की: 198743\n",
      "पर: 186484\n",
      "को: 153868\n",
      "से: 143492\n",
      "ने: 127227\n",
      "का: 117758\n",
      "और: 115482\n",
      "स: 88385\n",
      "कि: 86752\n",
      "य: 80503\n",
      "हैं: 80315\n",
      "कर: 72655\n",
      "भी: 65969\n",
      "ष: 65536\n",
      "ों: 58313\n",
      "एक: 57250\n",
      "क: 55157\n"
     ]
    }
   ],
   "source": [
    "# indicBert-Token-Unigram-Frequency(2000 max-length)\n",
    "indicBert_two_thou_unigram_top_frequency_dict = get_top_unigram_frequency(indicBert_two_thou_unigram_cleaned)\n",
    "for key,value in indicBert_two_thou_unigram_top_frequency_dict.items():\n",
    "    print(key + \": \" + str(value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "केलिए: 43496\n",
      "हैकि: 25058\n",
      "केसाथ: 18312\n",
      "होंने: 17726\n",
      "कहाकि: 16129\n",
      "नेकहा: 15563\n",
      "कष: 14580\n",
      "केबाद: 14411\n",
      "मंतरी: 12670\n",
      "रहाहै: 12020\n",
      "गयाहै: 11061\n",
      "ोंके: 10787\n",
      "उनहों: 10532\n",
      "कारय: 10251\n",
      "रहेहैं: 10178\n",
      "हैऔर: 10127\n",
      "राष: 9720\n",
      "दवारा: 9372\n",
      "उनहें: 9144\n",
      "ोंको: 9000\n"
     ]
    }
   ],
   "source": [
    "# indicBert-Token-Bigram-Frequency(2000 max-length)\n",
    "indic_two_thou_bigram_top_frequency_dict = get_top_bigram_frequency(indicBert_two_thou_unigram_cleaned)\n",
    "for key,value in indic_two_thou_bigram_top_frequency_dict.items():\n",
    "    print(key + \": \" + str(value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing characters of tokens\n",
    "indic_two_thou_characters_list_of_list = varn_viched_arr(indicBert_two_thou_unigram_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आ', 'व्', 'ए', 'द्', 'अ', 'न्', 'अ', 'क्', 'अ', 'र्']\n"
     ]
    }
   ],
   "source": [
    "# Convert list of list to list\n",
    "indic_two_thou_characters_list = []\n",
    "for list_arr in indic_two_thou_characters_list_of_list:\n",
    "    for word in list_arr:\n",
    "        indic_two_thou_characters_list.append(word)\n",
    "print(indic_two_thou_characters_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "अ 9021271\n",
      "आ 2991109\n",
      "ए 2318442\n",
      "क् 2221101\n",
      "र् 2115912\n",
      "ई 1460305\n",
      "इ 1432973\n",
      "न् 1335232\n",
      "स् 1283708\n",
      "अं 1201207\n",
      "ह् 1133159\n",
      "म् 1053237\n",
      "त् 980066\n",
      "ल् 919917\n",
      "ओ 896588\n",
      "प् 805896\n",
      "य् 753228\n",
      "व् 624743\n",
      "द् 607633\n",
      "उ 587149\n"
     ]
    }
   ],
   "source": [
    "# indicBert-Character-Unigram-Frequency(2000 max_length)\n",
    "indic_two_thou_character_unigram_top_frequency_dict = get_top_unigram_frequency(indic_two_thou_characters_list)\n",
    "for key,value in indic_two_thou_character_unigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र्अ 1525832\n",
      "अर् 1206308\n",
      "अक् 997512\n",
      "क्अ 805473\n",
      "स्अ 702627\n",
      "न्अ 635322\n",
      "अह् 591176\n",
      "अन् 585022\n",
      "प्अ 555241\n",
      "अम् 531558\n",
      "त्अ 522037\n",
      "अत् 471335\n",
      "अस् 438049\n",
      "ल्अ 427792\n",
      "क्ए 403275\n",
      "आर् 400534\n",
      "म्अ 384518\n",
      "एअं 363519\n",
      "अल् 342759\n",
      "अय् 341016\n"
     ]
    }
   ],
   "source": [
    "## indicBert-Character-Bigram-Frequency(2000 max_length)\n",
    "indic_two_thou_character_bigram_top_frequency_dict = get_top_bigram_frequency(indic_two_thou_characters_list)\n",
    "for key,value in indic_two_thou_character_bigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicBert-Syllables(2000 max-length)\n",
    "indic_two_thou_syllables_list_of_list = convert_list_of_words_to_list_of_syllables(indic_two_thou_characters_list_of_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicBert Converting list of list to list\n",
    "indic_two_thou_syllables_list = []\n",
    "for list_arr in indic_two_thou_syllables_list_of_list:\n",
    "    for word in list_arr:\n",
    "        indic_two_thou_syllables_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र 1520979\n",
      "क 801973\n",
      "स 701122\n",
      "न 631966\n",
      "प 553528\n",
      "त 521976\n",
      "ल 423355\n",
      "के 401315\n",
      "म 382930\n",
      "ने 322671\n",
      "आ 317459\n",
      "य 306052\n",
      "का 295482\n",
      "ह 293243\n",
      "ब 279336\n",
      "ग 277979\n",
      "इ 274450\n",
      "या 271454\n",
      "व 266429\n",
      "ज 263566\n"
     ]
    }
   ],
   "source": [
    "# indicBert-Syllables-Unigram-Frequency(2000 max_length)\n",
    "indic_two_thou_syllables_unigram_top_frequency_dict = get_top_unigram_frequency(indic_two_thou_syllables_list)\n",
    "for key,value in indic_two_thou_syllables_unigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "पर 221155\n",
      "कर 197336\n",
      "और 116389\n",
      "इस 94077\n",
      "तर 78366\n",
      "कार 65862\n",
      "ओअं 64653\n",
      "एक 64396\n",
      "उन 57364\n",
      "रक 48988\n",
      "नहीं 48049\n",
      "अप 47798\n",
      "केलिे 47128\n",
      "तक 46834\n",
      "दर 45558\n",
      "रआ 45534\n",
      "रने 44746\n",
      "रत 43364\n",
      "कष 43095\n",
      "टर 42554\n"
     ]
    }
   ],
   "source": [
    "## indic-Syllables-Bigram-Frequency(2000 max-length)\n",
    "indic_two_thou_syllables_bigram_top_frequency_dict = get_top_bigram_frequency(indic_two_thou_syllables_list)\n",
    "for key,value in indic_two_thou_syllables_bigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## White Space Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "विकेट\n"
     ]
    }
   ],
   "source": [
    "def white_space_tokenizer(line):\n",
    "    return line.split()\n",
    "white_space_tokens = []\n",
    "for line in dataset_2:\n",
    "    white_space_tokens.extend(white_space_tokenizer(line))\n",
    "print(white_space_tokens[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "के 316314\n",
      "में 237426\n",
      "की 189769\n",
      "को 145266\n",
      "से 136979\n",
      "और 114563\n",
      "का 109743\n",
      "ने 102378\n",
      "पर 88560\n",
      "है। 88260\n",
      "कि 76741\n",
      "है 72656\n",
      "भी 63920\n",
      "एक 49279\n",
      "लिए 47955\n",
      "इस 47558\n",
      "कर 44563\n",
      "नहीं 44168\n",
      "ही 40104\n",
      "तो 33469\n"
     ]
    }
   ],
   "source": [
    "white_space_unigram_freq = get_top_unigram_frequency(white_space_tokens)\n",
    "for key,value in white_space_unigram_freq.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "केलिए 42448\n",
      "हैकि 24816\n",
      "केसाथ 17075\n",
      "कहाकि 15922\n",
      "केबाद 14163\n",
      "हैऔर 10096\n",
      "नेकहा 9098\n",
      "करनेके 8826\n",
      "बतायाकि 6392\n",
      "कोलेकर 5977\n",
      "गयाहै। 5678\n",
      "रहाहै। 5483\n",
      "केखिलाफ 5312\n",
      "केदौरान 5162\n",
      "केबीच 5117\n",
      "बारेमें 5059\n",
      "करतेहुए 4817\n",
      "रहेहैं। 4701\n",
      "मेंभी 4682\n",
      "कररहे 4637\n"
     ]
    }
   ],
   "source": [
    "white_space_bigram_freq = get_top_bigram_frequency(white_space_tokens)\n",
    "for key,value in white_space_bigram_freq.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing characters of tokens\n",
    "white_space_characters_list_of_list = varn_viched_arr(white_space_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आ', 'व्', 'ए', 'द्', 'अ', 'न्', 'अ', 'क्', 'अ', 'र्']\n"
     ]
    }
   ],
   "source": [
    "# Convert list of list to list\n",
    "white_space_characters_list = []\n",
    "for list_arr in white_space_characters_list_of_list:\n",
    "    for word in list_arr:\n",
    "        white_space_characters_list.append(word)\n",
    "print(white_space_characters_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "अ 7020567\n",
      "आ 2991109\n",
      "ए 2318442\n",
      "क् 2219964\n",
      "र् 2115649\n",
      "ई 1460305\n",
      "इ 1432973\n",
      "न् 1334448\n",
      "स् 1283708\n",
      "अं 1201207\n",
      "ह् 1133159\n",
      "म् 1053237\n",
      "त् 980066\n",
      "ल् 919917\n",
      "ओ 896588\n",
      "प् 805896\n",
      "य् 752819\n",
      "व् 624743\n",
      "द् 607633\n",
      "उ 587149\n"
     ]
    }
   ],
   "source": [
    "# WhiteSpace-Character-Unigram-Frequency\n",
    "whiteSpace_unigram_top_frequency_dict = get_top_unigram_frequency(white_space_characters_list)\n",
    "for key,value in whiteSpace_unigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र्अ 1173434\n",
      "अक् 941795\n",
      "अर् 873350\n",
      "क्अ 616883\n",
      "अन् 556260\n",
      "अह् 552061\n",
      "स्अ 518747\n",
      "न्अ 515820\n",
      "अम् 459684\n",
      "क्ए 407258\n",
      "प्अ 405638\n",
      "आर् 400425\n",
      "अस् 392620\n",
      "एअं 363537\n",
      "त्अ 353274\n",
      "अत् 349063\n",
      "ल्अ 333296\n",
      "न्ए 328971\n",
      "म्अ 324907\n",
      "क्आ 314861\n"
     ]
    }
   ],
   "source": [
    "## whiteSpace-Character-Bigram-Frequency\n",
    "whiteSpace_character_bigram_top_frequency_dict = get_top_bigram_frequency(white_space_characters_list)\n",
    "for key,value in whiteSpace_character_bigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आ', 'व्', 'ए', 'द्', 'अ', 'न्', 'अ', 'क्', 'अ', 'र्']\n"
     ]
    }
   ],
   "source": [
    "print(white_space_characters_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whiteSpace-Syllables\n",
    "whiteSpace_syllables_list_of_list = convert_list_of_words_to_list_of_syllables(white_space_characters_list_of_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['आ', 'वे', 'द', 'न'], ['क', 'र', 'ने'], ['की'], ['आ', 'खि', 'री'], ['ता', 'री', 'ख'], [], ['ज', 'न', 'व', 'री'], [], ['है'], ['इ', 'त', 'नी'], ['दुा'], ['क', 'र'], ['दो'], ['ह', 'मा', 'रे'], ['लिे'], ['कि'], ['जि', 'त', 'ना'], ['प्या', 'र'], ['दु', 'नि', 'या'], ['ने'], ['आ', 'प', 'को'], ['दि', 'या'], ['है'], ['ब', 'स'], ['उ', 'त', 'ना'], ['ही'], ['ह', 'में'], ['भी'], ['मि', 'ल'], ['जाे'], ['मो', 'दी'], ['स', 'र', 'का', 'र'], ['के'], ['प', 'ह', 'ले'], ['का', 'र्य', 'का', 'ल'], ['में'], ['भी'], ['ती', 'न'], ['त', 'ला', 'क'], ['को'], ['ले', 'क', 'र'], ['बि', 'ल'], ['ला', 'या'], ['ग', 'या'], ['था'], ['हा', 'लां', 'कि'], ['त', 'ब'], ['य', 'ह'], ['रा', 'ज्य', 'स', 'भा'], ['में']]\n"
     ]
    }
   ],
   "source": [
    "print(whiteSpace_syllables_list_of_list[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whiteSpace Converting list of list to list\n",
    "whiteSpace_syllables_list = []\n",
    "for list_arr in whiteSpace_syllables_list_of_list:\n",
    "    for word in list_arr:\n",
    "        whiteSpace_syllables_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र 1004686\n",
      "क 594954\n",
      "न 501929\n",
      "स 485896\n",
      "के 395614\n",
      "प 387543\n",
      "ल 323592\n",
      "ने 321110\n",
      "त 305294\n",
      "म 290785\n",
      "का 289809\n",
      "ह 278330\n",
      "अ 269458\n",
      "में 259108\n",
      "ब 243812\n",
      "की 233082\n",
      "ग 223717\n",
      "है 215999\n",
      "या 211534\n",
      "से 210346\n"
     ]
    }
   ],
   "source": [
    "# whiteSpace-Syllables-Unigram-Frequency\n",
    "whiteSpace_syllables_unigram_top_frequency_dict = get_top_unigram_frequency(whiteSpace_syllables_list)\n",
    "for key,value in whiteSpace_syllables_unigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कर 159143\n",
      "और 115322\n",
      "पर 100372\n",
      "इस 81128\n",
      "एक 53821\n",
      "नहीं 47327\n",
      "अप 47171\n",
      "केलिे 47125\n",
      "रने 44025\n",
      "तक 41042\n",
      "कार 39734\n",
      "किया 37071\n",
      "ताहै 35416\n",
      "नेके 34454\n",
      "सके 34052\n",
      "नके 32688\n",
      "कहा 32593\n",
      "रका 32469\n",
      "यह 31309\n",
      "सर 30702\n"
     ]
    }
   ],
   "source": [
    "## WhiteSpace-Syllables-Bigram-Frequency(1000 max-length)\n",
    "whiteSpace_syllables_bigram_top_frequency_dict = get_top_bigram_frequency(whiteSpace_syllables_list)\n",
    "for key,value in whiteSpace_syllables_bigram_top_frequency_dict.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ques_3.txt', encoding='utf-8') as f:\n",
    "    # Read the content of the file and split it into lines\n",
    "    dataset = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "अगर आपको व्यापार में सफलता मिल रही है तो अपने घर के उत्तर पूर्व कोने को गंगाजल से धोकर वहां हल्दी का स्वास्तिक बनाये। फिर उसकी पूजा करे गुड़ का भोग लगाए। ऐसा करने से आपके व्यापार में सफलता बढेगी साथ ही आप जीवन में सफलता की सीढी भी चढेंगे।\n",
      "['अगर', 'आपको', 'व्यापारमें', 'सफलता', 'मिलरहीहै', 'तो', 'अपने', 'घरके', 'उत्तरपूर्वकोनेको', 'गंगाजलसे', 'धोकर', 'वहां', 'हल्दीका', 'स्वास्तिक', 'बनाये', '', 'फिरउसकी', 'पूजाकरे', 'गुड़का', 'भोग', 'लगाए', '', 'ऐसा', 'करनेसे', 'आपके', 'व्यापारमें', 'सफलता', 'बढेगी', 'साथही', 'आप', 'जीवनमें', 'सफलताकी', 'सीढी', 'भीचढेंगे']\n"
     ]
    }
   ],
   "source": [
    "# Fetching the question and their response\n",
    "data = []\n",
    "length = len(dataset)\n",
    "question_arr = []\n",
    "response_arr = []\n",
    "i=0\n",
    "while i<length:\n",
    "    question_arr.append(dataset[i][3:])\n",
    "    i+=1\n",
    "    responses = dataset[i].split(',')\n",
    "    cleaned_response = [response.strip().replace(\" \",\"\").replace(\"।\",\"\") for response in responses]\n",
    "    response_arr.append(cleaned_response)\n",
    "    i+=2\n",
    "print(question_arr[1])\n",
    "print(response_arr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁लेकिन', '▁मुझे', '▁नहीं', '▁प', 'ता', '▁था', '▁कि', '▁र', 'ु', 'थ', '▁के', '▁भ', 'ाई', '▁से', '▁शा', 'दी', '▁करने', '▁के', '▁बाद', '▁हम', '▁(', 'ज', 'ि', 'मी', '▁और', '▁रो', 'स', 'ल', 'िन', ')', '▁रह', 'ने', '▁के', '▁लिए', '▁उस', 'ी', '▁म', 'का', 'न', '▁में', '▁प्र', 'व', 'ेश', '▁कर', 'ेंगे', '”', '▁|']\n",
      "['▁लेकिन', '▁मु', 'झे', '▁नहीं', '▁प', 'ता', '▁था', '▁कि', '▁रु', 'थ', '▁के', '▁भा', 'ई', '▁से', '▁शा', 'दी', '▁करने', '▁के', '▁बाद', '▁हम', '▁(', 'ज', 'िम', 'ी', '▁और', '▁रो', 'स', 'ल', 'िन', ')', '▁रह', 'ने', '▁के', '▁लिए', '▁उ', 'सी', '▁म', 'क', 'ान', '▁में', '▁प्र', 'व', 'ेश', '▁कर', 'ेंगे', '”', '▁|']\n",
      "['▁लेकिन', '▁मुझे', '▁नहीं', '▁पता', '▁था', '▁कि', '▁रु', 'थ', '▁के', '▁भाई', '▁से', '▁शादी', '▁करने', '▁के', '▁बाद', '▁हम', '▁(', 'ज', 'िम', 'ी', '▁और', '▁रो', 'सल', 'िन', ')', '▁रहने', '▁के', '▁लिए', '▁उसी', '▁म', 'कान', '▁में', '▁प्र', 'वेश', '▁करेंगे', '”', '▁|']\n",
      "['लेकिन', 'म', '##ु', '##झ', '##े', 'नहीं', 'पता', 'था', 'कि', 'र', '##ु', '##थ', 'के', 'भ', '##ाई', 'से', 'श', '##ाद', '##ी', 'करने', 'के', 'बाद', 'हम', '(', 'ज', '##िम', '##ी', 'और', 'र', '##ो', '##स', '##ल', '##िन', ')', 'रहने', 'के', 'लिए', 'उस', '##ी', 'म', '##का', '##न', 'में', 'प्रवेश', 'कर', '##ें', '##गे', '[UNK]', '|']\n",
      "['लेकिन', 'म', '##ु', '##झ', '##े', 'नहीं', 'पता', 'था', 'कि', 'र', '##ु', '##थ', 'के', 'भ', '##ाई', 'से', 'श', '##ाद', '##ी', 'करने', 'के', 'बाद', 'हम', '(', 'ज', '##िम', '##ी', 'और', 'र', '##ो', '##स', '##ल', '##िन', ')', 'रहने', 'के', 'लिए', 'उस', '##ी', 'म', '##का', '##न', 'में', 'प्रवेश', 'कर', '##ें', '##गे', '[UNK]', '|']\n",
      "['▁लेकिन', '▁मुझे', '▁नहीं', '▁पता', '▁था', '▁कि', '▁रु', 'थ', '▁के', '▁भाई', '▁से', '▁शादी', '▁करने', '▁के', '▁बाद', '▁हम', '▁(', 'जिम', 'ी', '▁और', '▁', 'रोस', 'लिन', ')', '▁रहने', '▁के', '▁लिए', '▁उसी', '▁मकान', '▁में', '▁पर', 'वेश', '▁करेंगे', '”', '▁|']\n",
      "['लेकिन', 'मुझे', 'नहीं', 'पता', 'था', 'कि', 'रुथ', 'के', 'भाई', 'से', 'शादी', 'करने', 'के', 'बाद', 'हम', '(जिमी', 'और', 'रोसलिन)', 'रहने', 'के', 'लिए', 'उसी', 'मकान', 'में', 'प्रवेश', 'करेंगे”', '|']\n"
     ]
    }
   ],
   "source": [
    "# Tokens for all Tokenizer \n",
    "unigram_tokens = [sp_unigram.encode_as_pieces(line) for line in question_arr]\n",
    "bpe_thousand_tokens = [sp_bpe_thou.encode_as_pieces(line) for line in question_arr]\n",
    "bpe_two_thousand_tokens = [sp_bpe_two_thou.encode_as_pieces(line)  for line in question_arr]\n",
    "mBert_thousand_tokens = [tokenizer_thou.tokenize(line)  for line in question_arr]\n",
    "mBert_two_thousand_tokens = [tokenizer_two_thou.tokenize(line)  for line in question_arr]\n",
    "indicBert_thousand_tokens = [indic_tokenizer_thou.tokenize(line)  for line in question_arr]\n",
    "indicBert_two_thousand_tokens = [indic_tokenizer_two_thou.tokenize(line)  for line in question_arr]\n",
    "white_space_tokens = [white_space_tokenizer(line)  for line in question_arr]\n",
    "\n",
    "print(unigram_tokens[5])\n",
    "print(bpe_thousand_tokens[5])\n",
    "print(bpe_two_thousand_tokens[5])\n",
    "print(mBert_thousand_tokens[5])\n",
    "print(mBert_two_thousand_tokens[5])\n",
    "print(indicBert_thousand_tokens[5])\n",
    "print(white_space_tokens[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean tokens for all tokenizer\n",
    "unigram_tokens_cleaned = [clean_strings(tokens) for tokens in unigram_tokens]\n",
    "bpe_thousand_tokens_cleaned = [clean_strings(tokens) for tokens in bpe_thousand_tokens]\n",
    "bpe_two_thousand_tokens_cleaned = [clean_strings(tokens) for tokens in bpe_two_thousand_tokens]\n",
    "mBert_thousand_tokens_cleaned = [clean_bert(tokens) for tokens in mBert_thousand_tokens]\n",
    "mBert_two_thousand_tokens_cleaned= [clean_bert(tokens) for tokens in mBert_two_thousand_tokens] \n",
    "indicBert_thousand_tokens_cleaned = [clean_bert(tokens) for tokens in indicBert_thousand_tokens]\n",
    "indicBert_two_thousand_tokens_cleaned = [clean_bert(tokens)for tokens in indicBert_two_thousand_tokens ] \n",
    "white_space_tokens_cleaned = [clean_strings(tokens) for tokens in white_space_tokens] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Accuracy of tokenizer\n",
    "def get_accuracy(tokenizer_tokens,ground_truth):\n",
    "    cnt = 0\n",
    "    total = 0\n",
    "    length = len(ground_truth)\n",
    "    for i in range(length):\n",
    "        total += len(ground_truth[i])\n",
    "        for token in tokenizer_tokens[i]:\n",
    "            if token in ground_truth[i]:\n",
    "                cnt+=1\n",
    "    accuracy = cnt*100.0 /total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.40909090909091\n",
      "26.136363636363637\n",
      "29.166666666666668\n",
      "24.62121212121212\n",
      "24.62121212121212\n",
      "32.196969696969695\n",
      "32.196969696969695\n",
      "35.984848484848484\n"
     ]
    }
   ],
   "source": [
    "unigram_accuracy = get_accuracy(unigram_tokens_cleaned,response_arr)\n",
    "bpe_thousand_accuracy = get_accuracy(bpe_thousand_tokens_cleaned,response_arr)\n",
    "bpe_two_thousand_accuracy = get_accuracy(bpe_two_thousand_tokens_cleaned,response_arr)\n",
    "mBert_thousand_accuracy = get_accuracy(mBert_thousand_tokens_cleaned,response_arr)\n",
    "mBert_two_thousand_accuracy = get_accuracy(mBert_two_thousand_tokens_cleaned,response_arr)\n",
    "indicBert_thousand_accuracy = get_accuracy(indicBert_thousand_tokens_cleaned,response_arr)\n",
    "indicBert_two_thousand_accuracy = get_accuracy(indicBert_two_thousand_tokens_cleaned,response_arr)\n",
    "white_space_accuracy =  get_accuracy(white_space_tokens_cleaned,response_arr)\n",
    "\n",
    "print(unigram_accuracy)\n",
    "print(bpe_thousand_accuracy)\n",
    "print(bpe_two_thousand_accuracy)\n",
    "print(mBert_thousand_accuracy)\n",
    "print(mBert_two_thousand_accuracy)\n",
    "print(indicBert_thousand_accuracy)\n",
    "print(indicBert_two_thousand_accuracy)\n",
    "print(white_space_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP = Tokenizer generated and in ground truths\n",
    "# FP = Tokenizer generated but not in ground truths\n",
    "# TN = Tokenizer does not generated but also not in ground truths\n",
    "# FN = Tokenizer does not generated but in ground truths\n",
    "def compute_tp_fp_fn(tokenizer_tokens,ground_truth):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    length = len(ground_truth)\n",
    "    for i in range(length):\n",
    "        for token in tokenizer_tokens[i]:\n",
    "            if token in ground_truth[i]:\n",
    "                tp+=1\n",
    "            else:\n",
    "                fp+=1\n",
    "        for token in ground_truth[i]:\n",
    "            if token not in tokenizer_tokens[i]:\n",
    "                fn+=1\n",
    "    return [tp,fp,fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(tokenizer_tokens,ground_truth):\n",
    "    [tp,fp,fn] = compute_tp_fp_fn(tokenizer_tokens,ground_truth)\n",
    "    precision = tp / (tp+fp) if (tp+fp)>0 else 0\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall(tokenizer_tokens,ground_truth):\n",
    "    [tp,fp,fn] = compute_tp_fp_fn(tokenizer_tokens,ground_truth)\n",
    "    recall = tp / (tp + fn) if (tp+fn)>0 else 0\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fscore(tokenizer_tokens,ground_truth):\n",
    "    [tp,fp,fn] = compute_tp_fp_fn(tokenizer_tokens,ground_truth)\n",
    "    precision = tp / (tp+fp) if (tp+fp)>0 else 0\n",
    "    recall = tp / (tp + fn) if (tp+fn)>0 else 0\n",
    "    f_score = (2*precision*recall)/(precision+recall) if (precision + recall) > 0 else 0\n",
    "    return f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision\n",
    "unigram_precision = get_precision(unigram_tokens_cleaned, response_arr)\n",
    "bpe_thousand_precision = get_precision(bpe_thousand_tokens_cleaned, response_arr)\n",
    "bpe_two_thousand_precision = get_precision(bpe_two_thousand_tokens_cleaned, response_arr)\n",
    "mBert_thousand_precision = get_precision(mBert_thousand_tokens_cleaned, response_arr)\n",
    "mBert_two_thousand_precision = get_precision(mBert_two_thousand_tokens_cleaned, response_arr)\n",
    "indicBert_thousand_precision = get_precision(indicBert_thousand_tokens_cleaned, response_arr)\n",
    "indicBert_two_thousand_precision = get_precision(indicBert_two_thousand_tokens_cleaned, response_arr)\n",
    "white_space_precision = get_precision(white_space_tokens_cleaned, response_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Recall\n",
    "unigram_recall = get_recall(unigram_tokens_cleaned, response_arr)\n",
    "bpe_thousand_recall = get_recall(bpe_thousand_tokens_cleaned, response_arr)\n",
    "bpe_two_thousand_recall = get_recall(bpe_two_thousand_tokens_cleaned, response_arr)\n",
    "mBert_thousand_recall = get_recall(mBert_thousand_tokens_cleaned, response_arr)\n",
    "mBert_two_thousand_recall = get_recall(mBert_two_thousand_tokens_cleaned, response_arr)\n",
    "indicBert_thousand_recall = get_recall(indicBert_thousand_tokens_cleaned, response_arr)\n",
    "indicBert_two_thousand_recall = get_recall(indicBert_two_thousand_tokens_cleaned, response_arr)\n",
    "white_space_recall = get_recall(white_space_tokens_cleaned, response_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate F_Score\n",
    "unigram_fscore = get_fscore(unigram_tokens_cleaned, response_arr)\n",
    "bpe_thousand_fscore = get_fscore(bpe_thousand_tokens_cleaned, response_arr)\n",
    "bpe_two_thousand_fscore = get_fscore(bpe_two_thousand_tokens_cleaned, response_arr)\n",
    "mBert_thousand_fscore = get_fscore(mBert_thousand_tokens_cleaned, response_arr)\n",
    "mBert_two_thousand_fscore = get_fscore(mBert_two_thousand_tokens_cleaned, response_arr)\n",
    "indicBert_thousand_fscore = get_fscore(indicBert_thousand_tokens_cleaned, response_arr)\n",
    "indicBert_two_thousand_fscore = get_fscore(indicBert_two_thousand_tokens_cleaned, response_arr)\n",
    "white_space_fscore = get_fscore(white_space_tokens_cleaned, response_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Model   Accuracy  Precision    Recall   F-score\n",
      "0                 Unigram  28.409091   0.079281  0.280899  0.123660\n",
      "1            BPE Thousand  26.136364   0.071061  0.257463  0.111380\n",
      "2        BPE Two Thousand  29.166667   0.094247  0.286245  0.141805\n",
      "3          mBERT Thousand  24.621212   0.071429  0.241636  0.110263\n",
      "4      mBERT Two Thousand  24.621212   0.071429  0.241636  0.110263\n",
      "5      IndicBERT Thousand  32.196970   0.128012  0.314815  0.182013\n",
      "6  IndicBERT Two Thousand  32.196970   0.128012  0.314815  0.182013\n",
      "7             White Space  35.984848   0.202559  0.350554  0.256757\n"
     ]
    }
   ],
   "source": [
    "# Comparision of all modals\n",
    "# -------------------------------------------------- NOTe ------------------------------------------------------------------\n",
    "# Accuracy in 100\n",
    "# Precision , Recall , F-Score on scale of 0 to 1\n",
    "# -------------------------------------------------- NOTe ------------------------------------------------------------------\n",
    "data = {\n",
    "    'Model': ['Unigram', 'BPE Thousand', 'BPE Two Thousand', 'mBERT Thousand', 'mBERT Two Thousand', 'IndicBERT Thousand', 'IndicBERT Two Thousand', 'White Space'],\n",
    "    'Accuracy': [unigram_accuracy, bpe_thousand_accuracy, bpe_two_thousand_accuracy, mBert_thousand_accuracy, mBert_two_thousand_accuracy, indicBert_thousand_accuracy, indicBert_two_thousand_accuracy, white_space_accuracy],\n",
    "    'Precision': [unigram_precision, bpe_thousand_precision, bpe_two_thousand_precision, mBert_thousand_precision, mBert_two_thousand_precision, indicBert_thousand_precision, indicBert_two_thousand_precision, white_space_precision],\n",
    "    'Recall': [unigram_recall, bpe_thousand_recall, bpe_two_thousand_recall, mBert_thousand_recall, mBert_two_thousand_recall, indicBert_thousand_recall, indicBert_two_thousand_recall, white_space_recall],\n",
    "    'F-score': [unigram_fscore, bpe_thousand_fscore, bpe_two_thousand_fscore, mBert_thousand_fscore, mBert_two_thousand_fscore, indicBert_thousand_fscore, indicBert_two_thousand_fscore, white_space_fscore]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on scale of 100 and Precision Recall F-Score on Scale of 0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "\n",
    "#### Comparison between models:\n",
    "1. **Low Precision:** All models (Unigram, BPE, mBERT, IndicBERT, White Space) exhibit very low precision, indicating a high number of false positives, i.e., incorrect word group predictions.\n",
    "\n",
    "2. **Low Recall:** Similarly, all models demonstrate low recall, suggesting that they miss a significant number of relevant word groups, failing to identify a large portion of actual word groups.\n",
    "\n",
    "3. **Low F-Score:** The F-score for all models is very low, indicating poor overall performance in tokenization tasks.\n",
    "\n",
    "4. **Low Accuracy:** All models exhibit low accuracy, implying that their predictions are incorrect more often than they are correct, highlighting a lack of effectiveness in tokenization tasks.\n",
    "\n",
    "5. **mBERT Performance:** mBERT performs worse than BPE and Unigram, suggesting a potential skew towards certain languages.\n",
    "\n",
    "6. **IndicBERT Performance:** IndicBERT outperforms mBERT, BPE, and Unigram, indicating its effectiveness in handling Hindi text.\n",
    "\n",
    "7. **White Space Tokenization:** Surprisingly, White Space tokenization outperforms the others overall, suggesting that simple tokenization might be effective.\n",
    "\n",
    "8. **Vocabulary Size Impact:** Among each model, those with a larger vocabulary size generally perform slightly better (e.g., BPE Two Thousand vs. BPE Thousand).\n",
    "\n",
    "9. **Training Data Impact:** Training on larger datasets yields better results for all models.\n",
    "\n",
    "#### Failures of all Models:\n",
    "1. **Vibhakti Categorization:** All models fail to categorize inflectional endings correctly, often separating them from the main word.\n",
    "    - Example: \"Ram ko accha laga\" should have \"Ram\" grouped with \"ko\".\n",
    "\n",
    "2. **Auxiliary Verbs:** Indian languages frequently form compound verbs by combining auxiliary verbs with main verbs, which models fail to recognize.\n",
    "    - Example: In \"khelne laga hu\", where \"khelne\" should be combined with \"laga hu\", models fail to do so.\n",
    "\n",
    "3. **Compound Words:** Models fail to recognize compound words as one token.\n",
    "    - Example 1: \"Bharatiye Janta Party\" should be one token.\n",
    "    - Example 2: \"Uttar Pradesh\" should be one token.\n",
    "\n",
    "4. **Postpositions:** Models fail to group words correctly when postpositions are involved.\n",
    "    - Example: \"bhai se\" where \"bhai\" is a noun and \"se\" is a postposition and both should be together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e956c49ae0caa224b5fdd754cbc353d7e61c6c61f7329ee680c7f7b4f1b71a8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
